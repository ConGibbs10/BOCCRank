> 
> # parse arguments
> args <- R.utils::commandArgs(trailingOnly = FALSE, asValues = TRUE)
> index <- as.integer(args$index)
> year <- as.character(args$year)
> nreps <- as.integer(args$nreps)
> seed <- as.integer(args$seed)
> 
> # get number of cores
> wkrs <- length(future::availableWorkers())
> 
> # set seed
> set.seed(seed)
> 
> # read and prepare the cluster features
> fp <- file.path('data-raw', 'features', year)
> clf <-
+   read_features(fp, pattern = 'paris.', recursive = FALSE)
> clf <- prepare_features(
+   clf,
+   feature_map = feature_map,
+   category = c('response', 'bio', 'net'),
+   type = 'list',
+   exclusions = c(
+     'mg2_pairs_count',
+     'mg2_not_pairs_count',
+     'mg2_portion_families_recovered',
+     'cluster_origin',
+     'bocc_origin',
+     'cluster_method',
+     'subcluster_method',
+     'year',
+     'IDs',
+     'go_sig_threshold',
+     'num_new_edges_on_any_node',
+     'HPO_ratio'
+   ),
+   verbose = TRUE
+ )
c('HPO_ratio', 'IDs', 'bocc_origin', 'cluster_method', 'cluster_origin', 'go_sig_threshold', 'max_norm_cell_type_comma_sep_string', 'max_norm_disease_comma_sep_string', 'mg2_not_pairs_count', 'mg2_pairs_count', 'mg2_portion_families_recovered', 'num_new_edges_on_any_node', 'sig_go_enrichment_fdr_corrected_p_vals', 'sig_go_enrichment_p_vals', 'sig_go_enrichment_terms', 'subcluster_method', 'year')

> 
> # prepare grid of parameters
> xgboost_params <- dials::parameters(
+   nrounds = dials::trees(),
+   eta = dials::learn_rate(),
+   gamma = dials::loss_reduction(),
+   dials::tree_depth(),
+   subsample = dials::sample_prop(),
+   rate_drop = dials::dropout(),
+   skip_drop = dials::dropout()
+ )
> xgboost_params <-
+   dials::grid_max_entropy(xgboost_params, size = nreps)
> 
> # tune the dart booster
> dart.param <-
+   list(
+     booster = "dart",
+     objective = "reg:logistic",
+     eval_metric = "rmse",
+     nthread = wkrs,
+     max_depth = xgboost_params$tree_depth[index],
+     eta = xgboost_params$eta[index],
+     gamma = xgboost_params$gamma[index],
+     subsample = xgboost_params$subsample[index],
+     rate_drop = xgboost_params$rate_drop[index],
+     skip_drop = xgboost_params$skip_drop[index]
+   )
> dart.cv <- xgboost::xgb.cv(
+   params = dart.param,
+   nrounds = xgboost_params$nrounds[index],
+   data = as.matrix(clf[, -1]),
+   nfold = 5,
+   label = clf$snowballing_pvalue,
+   early_stopping_rounds = 50
+ )
[1]	train-rmse:0.396401+0.001251	test-rmse:0.396729+0.003686 
Multiple eval metrics are present. Will use test_rmse for early stopping.
Will train until test_rmse hasn't improved in 50 rounds.

[2]	train-rmse:0.378434+0.001189	test-rmse:0.379674+0.003729 
[3]	train-rmse:0.368336+0.003821	test-rmse:0.369815+0.007224 
[4]	train-rmse:0.358671+0.006289	test-rmse:0.360654+0.004766 
[5]	train-rmse:0.352508+0.008426	test-rmse:0.354425+0.009941 
[6]	train-rmse:0.346938+0.006395	test-rmse:0.348897+0.009861 
[7]	train-rmse:0.344653+0.006177	test-rmse:0.346591+0.009826 
[8]	train-rmse:0.342676+0.006063	test-rmse:0.344677+0.009829 
[9]	train-rmse:0.338725+0.009538	test-rmse:0.340609+0.014182 
[10]	train-rmse:0.337317+0.009424	test-rmse:0.339267+0.014184 
[11]	train-rmse:0.331514+0.013401	test-rmse:0.333491+0.017126 
[12]	train-rmse:0.330387+0.013224	test-rmse:0.332409+0.017065 
[13]	train-rmse:0.329384+0.013066	test-rmse:0.331476+0.017020 
[14]	train-rmse:0.328466+0.012897	test-rmse:0.330586+0.016931 
[15]	train-rmse:0.327609+0.012725	test-rmse:0.329762+0.016858 
[16]	train-rmse:0.326824+0.012620	test-rmse:0.328997+0.016823 
[17]	train-rmse:0.324141+0.015862	test-rmse:0.326026+0.021017 
[18]	train-rmse:0.321281+0.016913	test-rmse:0.323182+0.021094 
[19]	train-rmse:0.318291+0.016237	test-rmse:0.320642+0.019703 
[20]	train-rmse:0.315242+0.014831	test-rmse:0.317788+0.019337 
[21]	train-rmse:0.314711+0.014734	test-rmse:0.317281+0.019297 
[22]	train-rmse:0.314223+0.014616	test-rmse:0.316814+0.019230 
[23]	train-rmse:0.313762+0.014567	test-rmse:0.316365+0.019219 
[24]	train-rmse:0.313318+0.014469	test-rmse:0.315939+0.019163 
[25]	train-rmse:0.312893+0.014409	test-rmse:0.315514+0.019148 
[26]	train-rmse:0.309927+0.010481	test-rmse:0.313088+0.016748 
[27]	train-rmse:0.309553+0.010420	test-rmse:0.312737+0.016721 
[28]	train-rmse:0.309183+0.010379	test-rmse:0.312373+0.016714 
[29]	train-rmse:0.308847+0.010308	test-rmse:0.312043+0.016675 
[30]	train-rmse:0.308525+0.010259	test-rmse:0.311743+0.016642 
[31]	train-rmse:0.305733+0.007973	test-rmse:0.309468+0.015037 
[32]	train-rmse:0.303589+0.009254	test-rmse:0.307331+0.015101 
[33]	train-rmse:0.301277+0.011880	test-rmse:0.305050+0.016169 
[34]	train-rmse:0.301013+0.011832	test-rmse:0.304797+0.016148 
[35]	train-rmse:0.300745+0.011780	test-rmse:0.304533+0.016118 
[36]	train-rmse:0.298744+0.013614	test-rmse:0.302493+0.018969 
[37]	train-rmse:0.297029+0.015485	test-rmse:0.300858+0.019889 
[38]	train-rmse:0.294512+0.013819	test-rmse:0.298157+0.019469 
[39]	train-rmse:0.294311+0.013773	test-rmse:0.297949+0.019446 
[40]	train-rmse:0.292744+0.015791	test-rmse:0.296317+0.020614 
[41]	train-rmse:0.292544+0.015733	test-rmse:0.296133+0.020577 
[42]	train-rmse:0.292358+0.015674	test-rmse:0.295947+0.020533 
[43]	train-rmse:0.292167+0.015619	test-rmse:0.295767+0.020508 
[44]	train-rmse:0.289870+0.014267	test-rmse:0.293858+0.019057 
[45]	train-rmse:0.288403+0.016348	test-rmse:0.292390+0.020340 
[46]	train-rmse:0.288244+0.016293	test-rmse:0.292248+0.020300 
[47]	train-rmse:0.285933+0.014168	test-rmse:0.290458+0.018051 
[48]	train-rmse:0.283677+0.013199	test-rmse:0.288491+0.016023 
[49]	train-rmse:0.281899+0.012263	test-rmse:0.287129+0.014822 
[50]	train-rmse:0.281771+0.012230	test-rmse:0.287014+0.014805 
[51]	train-rmse:0.281647+0.012201	test-rmse:0.286885+0.014785 
[52]	train-rmse:0.279511+0.009971	test-rmse:0.284603+0.014421 
[53]	train-rmse:0.279390+0.009945	test-rmse:0.284484+0.014415 
[54]	train-rmse:0.279276+0.009918	test-rmse:0.284376+0.014398 
[55]	train-rmse:0.277430+0.009509	test-rmse:0.282948+0.013262 
[56]	train-rmse:0.277324+0.009495	test-rmse:0.282844+0.013264 
[57]	train-rmse:0.277217+0.009476	test-rmse:0.282741+0.013254 
[58]	train-rmse:0.277121+0.009462	test-rmse:0.282652+0.013257 
[59]	train-rmse:0.277022+0.009437	test-rmse:0.282557+0.013247 
[60]	train-rmse:0.276925+0.009417	test-rmse:0.282458+0.013245 
[61]	train-rmse:0.275216+0.008216	test-rmse:0.280621+0.013799 
[62]	train-rmse:0.273235+0.007015	test-rmse:0.279007+0.011582 
[63]	train-rmse:0.271630+0.006537	test-rmse:0.277391+0.012770 
[64]	train-rmse:0.271553+0.006526	test-rmse:0.277314+0.012772 
[65]	train-rmse:0.271475+0.006516	test-rmse:0.277249+0.012766 
[66]	train-rmse:0.271397+0.006502	test-rmse:0.277175+0.012761 
[67]	train-rmse:0.271321+0.006492	test-rmse:0.277108+0.012758 
[68]	train-rmse:0.271247+0.006480	test-rmse:0.277035+0.012759 
[69]	train-rmse:0.271177+0.006468	test-rmse:0.276965+0.012759 
[70]	train-rmse:0.271101+0.006456	test-rmse:0.276892+0.012749 
[71]	train-rmse:0.271033+0.006452	test-rmse:0.276826+0.012751 
[72]	train-rmse:0.270962+0.006436	test-rmse:0.276761+0.012756 
[73]	train-rmse:0.270897+0.006433	test-rmse:0.276694+0.012761 
[74]	train-rmse:0.270824+0.006424	test-rmse:0.276630+0.012762 
[75]	train-rmse:0.270754+0.006413	test-rmse:0.276559+0.012761 
[76]	train-rmse:0.270690+0.006404	test-rmse:0.276499+0.012766 
[77]	train-rmse:0.269587+0.008346	test-rmse:0.275486+0.013503 
[78]	train-rmse:0.269526+0.008331	test-rmse:0.275423+0.013498 
[79]	train-rmse:0.267651+0.008148	test-rmse:0.273939+0.012141 
[80]	train-rmse:0.267590+0.008139	test-rmse:0.273884+0.012135 
[81]	train-rmse:0.267535+0.008130	test-rmse:0.273831+0.012133 
[82]	train-rmse:0.267477+0.008123	test-rmse:0.273774+0.012134 
[83]	train-rmse:0.267425+0.008116	test-rmse:0.273721+0.012135 
[84]	train-rmse:0.263226+0.009390	test-rmse:0.269789+0.012380 
[85]	train-rmse:0.263180+0.009380	test-rmse:0.269745+0.012377 
[86]	train-rmse:0.263131+0.009367	test-rmse:0.269698+0.012375 
[87]	train-rmse:0.263083+0.009359	test-rmse:0.269655+0.012379 
[88]	train-rmse:0.263033+0.009348	test-rmse:0.269609+0.012376 
[89]	train-rmse:0.260821+0.010888	test-rmse:0.267618+0.012463 
[90]	train-rmse:0.259384+0.009022	test-rmse:0.266107+0.013049 
[91]	train-rmse:0.259342+0.009013	test-rmse:0.266068+0.013049 
[92]	train-rmse:0.259303+0.009002	test-rmse:0.266029+0.013048 
[93]	train-rmse:0.259267+0.008992	test-rmse:0.265994+0.013048 
[94]	train-rmse:0.259230+0.008983	test-rmse:0.265956+0.013042 
[95]	train-rmse:0.259194+0.008973	test-rmse:0.265920+0.013042 
[96]	train-rmse:0.259156+0.008965	test-rmse:0.265887+0.013039 
[97]	train-rmse:0.259122+0.008959	test-rmse:0.265852+0.013036 
[98]	train-rmse:0.257709+0.007677	test-rmse:0.264160+0.014425 
[99]	train-rmse:0.257676+0.007671	test-rmse:0.264129+0.014416 
[100]	train-rmse:0.256847+0.009201	test-rmse:0.263470+0.014960 
[101]	train-rmse:0.256814+0.009193	test-rmse:0.263439+0.014960 
[102]	train-rmse:0.256784+0.009183	test-rmse:0.263409+0.014956 
[103]	train-rmse:0.256752+0.009173	test-rmse:0.263380+0.014953 
[104]	train-rmse:0.256719+0.009161	test-rmse:0.263350+0.014949 
[105]	train-rmse:0.256687+0.009152	test-rmse:0.263318+0.014948 
[106]	train-rmse:0.256655+0.009143	test-rmse:0.263281+0.014942 
[107]	train-rmse:0.256625+0.009135	test-rmse:0.263251+0.014939 
[108]	train-rmse:0.256596+0.009127	test-rmse:0.263223+0.014937 
[109]	train-rmse:0.256567+0.009117	test-rmse:0.263198+0.014935 
[110]	train-rmse:0.255437+0.008666	test-rmse:0.262023+0.016156 
[111]	train-rmse:0.255412+0.008657	test-rmse:0.261995+0.016158 
[112]	train-rmse:0.253117+0.007670	test-rmse:0.259791+0.015830 
[113]	train-rmse:0.251794+0.007458	test-rmse:0.259055+0.015090 
[114]	train-rmse:0.251772+0.007450	test-rmse:0.259033+0.015091 
[115]	train-rmse:0.250510+0.007162	test-rmse:0.258176+0.014059 
[116]	train-rmse:0.249764+0.007096	test-rmse:0.257294+0.015343 
[117]	train-rmse:0.249743+0.007090	test-rmse:0.257276+0.015339 
[118]	train-rmse:0.249722+0.007084	test-rmse:0.257254+0.015336 
[119]	train-rmse:0.248653+0.005535	test-rmse:0.256306+0.015559 
[120]	train-rmse:0.248635+0.005529	test-rmse:0.256287+0.015561 
[121]	train-rmse:0.248615+0.005526	test-rmse:0.256270+0.015555 
[122]	train-rmse:0.248596+0.005521	test-rmse:0.256252+0.015554 
[123]	train-rmse:0.248577+0.005517	test-rmse:0.256235+0.015560 
[124]	train-rmse:0.247562+0.004479	test-rmse:0.255044+0.016150 
[125]	train-rmse:0.246422+0.004560	test-rmse:0.254273+0.015302 
[126]	train-rmse:0.245355+0.004024	test-rmse:0.253004+0.016266 
[127]	train-rmse:0.245340+0.004025	test-rmse:0.252990+0.016264 
[128]	train-rmse:0.244568+0.005343	test-rmse:0.252272+0.016488 
[129]	train-rmse:0.243740+0.004934	test-rmse:0.251263+0.017692 
[130]	train-rmse:0.243108+0.004967	test-rmse:0.250598+0.018550 
[131]	train-rmse:0.242443+0.006092	test-rmse:0.250022+0.018730 
[132]	train-rmse:0.242429+0.006086	test-rmse:0.250006+0.018726 
[133]	train-rmse:0.242417+0.006081	test-rmse:0.249993+0.018720 
[134]	train-rmse:0.241792+0.007191	test-rmse:0.249380+0.018982 
[135]	train-rmse:0.240008+0.006857	test-rmse:0.247647+0.018695 
[136]	train-rmse:0.239998+0.006849	test-rmse:0.247639+0.018688 
[137]	train-rmse:0.239986+0.006844	test-rmse:0.247628+0.018686 
[138]	train-rmse:0.239079+0.006909	test-rmse:0.246741+0.019400 
[139]	train-rmse:0.239070+0.006902	test-rmse:0.246730+0.019393 
[140]	train-rmse:0.239060+0.006897	test-rmse:0.246721+0.019393 
[141]	train-rmse:0.239050+0.006890	test-rmse:0.246710+0.019392 
[142]	train-rmse:0.239041+0.006885	test-rmse:0.246701+0.019389 
[143]	train-rmse:0.238472+0.007150	test-rmse:0.246192+0.019856 
[144]	train-rmse:0.237724+0.006986	test-rmse:0.245411+0.020704 
[145]	train-rmse:0.237718+0.006977	test-rmse:0.245405+0.020699 
[146]	train-rmse:0.237235+0.007285	test-rmse:0.244893+0.021166 
[147]	train-rmse:0.237227+0.007278	test-rmse:0.244887+0.021162 
[148]	train-rmse:0.237219+0.007272	test-rmse:0.244880+0.021158 
[149]	train-rmse:0.237211+0.007264	test-rmse:0.244872+0.021155 
[150]	train-rmse:0.236581+0.008066	test-rmse:0.244142+0.021375 
[151]	train-rmse:0.236575+0.008057	test-rmse:0.244136+0.021369 
[152]	train-rmse:0.236106+0.008036	test-rmse:0.243826+0.021694 
[153]	train-rmse:0.236099+0.008027	test-rmse:0.243819+0.021690 
[154]	train-rmse:0.236091+0.008020	test-rmse:0.243814+0.021687 
[155]	train-rmse:0.236083+0.008013	test-rmse:0.243806+0.021685 
[156]	train-rmse:0.236077+0.008007	test-rmse:0.243798+0.021683 
[157]	train-rmse:0.235539+0.008747	test-rmse:0.243404+0.021831 
[158]	train-rmse:0.235032+0.009503	test-rmse:0.243084+0.021968 
[159]	train-rmse:0.235025+0.009496	test-rmse:0.243081+0.021968 
[160]	train-rmse:0.233453+0.008004	test-rmse:0.241904+0.021358 
[161]	train-rmse:0.233449+0.007997	test-rmse:0.241901+0.021353 
[162]	train-rmse:0.232544+0.006916	test-rmse:0.241147+0.020435 
[163]	train-rmse:0.232540+0.006911	test-rmse:0.241141+0.020430 
[164]	train-rmse:0.231675+0.006354	test-rmse:0.240528+0.019715 
[165]	train-rmse:0.231671+0.006349	test-rmse:0.240521+0.019713 
[166]	train-rmse:0.231668+0.006345	test-rmse:0.240519+0.019710 
[167]	train-rmse:0.230621+0.006854	test-rmse:0.239814+0.019149 
[168]	train-rmse:0.229318+0.006950	test-rmse:0.238624+0.018842 
[169]	train-rmse:0.229316+0.006945	test-rmse:0.238623+0.018839 
[170]	train-rmse:0.228986+0.007467	test-rmse:0.238390+0.018925 
[171]	train-rmse:0.228078+0.006316	test-rmse:0.237565+0.017802 
[172]	train-rmse:0.228077+0.006313	test-rmse:0.237561+0.017802 
[173]	train-rmse:0.228075+0.006310	test-rmse:0.237560+0.017799 
[174]	train-rmse:0.228074+0.006307	test-rmse:0.237558+0.017798 
[175]	train-rmse:0.228072+0.006304	test-rmse:0.237554+0.017796 
[176]	train-rmse:0.228071+0.006302	test-rmse:0.237551+0.017795 
[177]	train-rmse:0.228070+0.006299	test-rmse:0.237549+0.017794 
[178]	train-rmse:0.227424+0.006531	test-rmse:0.236935+0.017178 
[179]	train-rmse:0.227422+0.006529	test-rmse:0.236933+0.017174 
[180]	train-rmse:0.226609+0.005747	test-rmse:0.236470+0.016548 
[181]	train-rmse:0.225873+0.005377	test-rmse:0.236267+0.016282 
[182]	train-rmse:0.225873+0.005375	test-rmse:0.236267+0.016283 
[183]	train-rmse:0.225873+0.005375	test-rmse:0.236267+0.016285 
[184]	train-rmse:0.225873+0.005373	test-rmse:0.236265+0.016286 
[185]	train-rmse:0.225393+0.004811	test-rmse:0.235672+0.016984 
[186]	train-rmse:0.225394+0.004808	test-rmse:0.235674+0.016984 
[187]	train-rmse:0.225394+0.004807	test-rmse:0.235669+0.016982 
[188]	train-rmse:0.225394+0.004805	test-rmse:0.235668+0.016983 
[189]	train-rmse:0.225073+0.005381	test-rmse:0.235426+0.017058 
[190]	train-rmse:0.225073+0.005380	test-rmse:0.235423+0.017057 
[191]	train-rmse:0.225074+0.005378	test-rmse:0.235422+0.017057 
[192]	train-rmse:0.225074+0.005378	test-rmse:0.235421+0.017057 
[193]	train-rmse:0.225074+0.005378	test-rmse:0.235420+0.017056 
[194]	train-rmse:0.224570+0.004956	test-rmse:0.234691+0.017974 
[195]	train-rmse:0.224571+0.004953	test-rmse:0.234690+0.017975 
[196]	train-rmse:0.224571+0.004951	test-rmse:0.234690+0.017975 
[197]	train-rmse:0.224572+0.004949	test-rmse:0.234686+0.017974 
[198]	train-rmse:0.224279+0.005504	test-rmse:0.234123+0.018167 
[199]	train-rmse:0.223735+0.005156	test-rmse:0.233714+0.018457 
[200]	train-rmse:0.223736+0.005155	test-rmse:0.233713+0.018456 
[201]	train-rmse:0.223736+0.005152	test-rmse:0.233712+0.018455 
[202]	train-rmse:0.223737+0.005152	test-rmse:0.233714+0.018455 
[203]	train-rmse:0.223223+0.004828	test-rmse:0.233362+0.018897 
[204]	train-rmse:0.223224+0.004826	test-rmse:0.233362+0.018894 
[205]	train-rmse:0.223224+0.004824	test-rmse:0.233362+0.018894 
[206]	train-rmse:0.223224+0.004822	test-rmse:0.233362+0.018894 
[207]	train-rmse:0.222590+0.004460	test-rmse:0.233019+0.018464 
[208]	train-rmse:0.222591+0.004459	test-rmse:0.233020+0.018467 
[209]	train-rmse:0.222591+0.004458	test-rmse:0.233019+0.018468 
[210]	train-rmse:0.222181+0.004204	test-rmse:0.232428+0.018923 
[211]	train-rmse:0.221771+0.004104	test-rmse:0.231972+0.019317 
[212]	train-rmse:0.221772+0.004103	test-rmse:0.231971+0.019316 
[213]	train-rmse:0.221773+0.004101	test-rmse:0.231971+0.019314 
[214]	train-rmse:0.221498+0.004125	test-rmse:0.231615+0.019643 
[215]	train-rmse:0.220644+0.004234	test-rmse:0.231133+0.019255 
[216]	train-rmse:0.220178+0.004574	test-rmse:0.230550+0.019768 
[217]	train-rmse:0.220180+0.004572	test-rmse:0.230551+0.019769 
[218]	train-rmse:0.220181+0.004571	test-rmse:0.230554+0.019767 
[219]	train-rmse:0.219852+0.004231	test-rmse:0.230205+0.020151 
[220]	train-rmse:0.219853+0.004229	test-rmse:0.230204+0.020151 
[221]	train-rmse:0.219536+0.003979	test-rmse:0.230136+0.020230 
[222]	train-rmse:0.219537+0.003976	test-rmse:0.230138+0.020229 
[223]	train-rmse:0.219539+0.003974	test-rmse:0.230140+0.020228 
[224]	train-rmse:0.219540+0.003973	test-rmse:0.230140+0.020226 
[225]	train-rmse:0.219542+0.003972	test-rmse:0.230138+0.020225 
[226]	train-rmse:0.219545+0.003971	test-rmse:0.230138+0.020226 
[227]	train-rmse:0.219547+0.003970	test-rmse:0.230137+0.020223 
[228]	train-rmse:0.219326+0.004380	test-rmse:0.229961+0.020263 
[229]	train-rmse:0.219329+0.004379	test-rmse:0.229961+0.020265 
[230]	train-rmse:0.219330+0.004379	test-rmse:0.229961+0.020264 
[231]	train-rmse:0.219331+0.004378	test-rmse:0.229961+0.020265 
[232]	train-rmse:0.218756+0.004651	test-rmse:0.229621+0.020538 
[233]	train-rmse:0.218313+0.004958	test-rmse:0.229294+0.020744 
[234]	train-rmse:0.218032+0.004866	test-rmse:0.229142+0.020915 
[235]	train-rmse:0.218035+0.004864	test-rmse:0.229144+0.020916 
[236]	train-rmse:0.218036+0.004863	test-rmse:0.229144+0.020914 
[237]	train-rmse:0.217426+0.004233	test-rmse:0.228978+0.020706 
[238]	train-rmse:0.217426+0.004231	test-rmse:0.228978+0.020704 
[239]	train-rmse:0.217429+0.004230	test-rmse:0.228979+0.020702 
[240]	train-rmse:0.217144+0.004155	test-rmse:0.228588+0.021156 
[241]	train-rmse:0.217146+0.004154	test-rmse:0.228590+0.021156 
[242]	train-rmse:0.217148+0.004151	test-rmse:0.228591+0.021155 
[243]	train-rmse:0.217152+0.004150	test-rmse:0.228591+0.021154 
[244]	train-rmse:0.216579+0.004159	test-rmse:0.228160+0.020727 
[245]	train-rmse:0.216582+0.004158	test-rmse:0.228159+0.020728 
[246]	train-rmse:0.216584+0.004156	test-rmse:0.228160+0.020726 
[247]	train-rmse:0.216585+0.004154	test-rmse:0.228162+0.020724 
[248]	train-rmse:0.216588+0.004154	test-rmse:0.228162+0.020722 
[249]	train-rmse:0.216590+0.004153	test-rmse:0.228162+0.020720 
[250]	train-rmse:0.216592+0.004151	test-rmse:0.228161+0.020716 
[251]	train-rmse:0.216422+0.004120	test-rmse:0.228077+0.020817 
[252]	train-rmse:0.215873+0.003745	test-rmse:0.227818+0.020531 
[253]	train-rmse:0.215666+0.003658	test-rmse:0.227477+0.020845 
[254]	train-rmse:0.215668+0.003658	test-rmse:0.227477+0.020843 
[255]	train-rmse:0.215670+0.003657	test-rmse:0.227479+0.020844 
[256]	train-rmse:0.215180+0.003549	test-rmse:0.227128+0.020470 
[257]	train-rmse:0.215182+0.003550	test-rmse:0.227129+0.020469 
[258]	train-rmse:0.215185+0.003550	test-rmse:0.227130+0.020468 
[259]	train-rmse:0.215187+0.003550	test-rmse:0.227131+0.020469 
[260]	train-rmse:0.214972+0.003477	test-rmse:0.226915+0.020677 
[261]	train-rmse:0.214975+0.003476	test-rmse:0.226915+0.020675 
[262]	train-rmse:0.214765+0.003457	test-rmse:0.226708+0.020882 
[263]	train-rmse:0.214765+0.003456	test-rmse:0.226709+0.020881 
[264]	train-rmse:0.214355+0.003527	test-rmse:0.226369+0.020534 
[265]	train-rmse:0.213980+0.003105	test-rmse:0.226309+0.020452 
[266]	train-rmse:0.213391+0.002665	test-rmse:0.226464+0.020264 
[267]	train-rmse:0.213394+0.002665	test-rmse:0.226465+0.020263 
[268]	train-rmse:0.213276+0.002886	test-rmse:0.226409+0.020272 
[269]	train-rmse:0.213108+0.002717	test-rmse:0.226206+0.020502 
[270]	train-rmse:0.213111+0.002715	test-rmse:0.226209+0.020502 
[271]	train-rmse:0.213113+0.002714	test-rmse:0.226211+0.020501 
[272]	train-rmse:0.213116+0.002714	test-rmse:0.226213+0.020500 
[273]	train-rmse:0.213119+0.002713	test-rmse:0.226214+0.020499 
[274]	train-rmse:0.212786+0.002630	test-rmse:0.225974+0.020192 
[275]	train-rmse:0.212789+0.002629	test-rmse:0.225975+0.020192 
[276]	train-rmse:0.212563+0.002501	test-rmse:0.225883+0.020285 
[277]	train-rmse:0.212566+0.002501	test-rmse:0.225884+0.020285 
[278]	train-rmse:0.212510+0.002608	test-rmse:0.225890+0.020285 
[279]	train-rmse:0.212513+0.002608	test-rmse:0.225890+0.020285 
[280]	train-rmse:0.212515+0.002607	test-rmse:0.225890+0.020286 
[281]	train-rmse:0.212123+0.002661	test-rmse:0.225757+0.020149 
[282]	train-rmse:0.212125+0.002660	test-rmse:0.225758+0.020148 
[283]	train-rmse:0.211914+0.003026	test-rmse:0.225724+0.020153 
[284]	train-rmse:0.211916+0.003026	test-rmse:0.225724+0.020151 
[285]	train-rmse:0.211918+0.003027	test-rmse:0.225724+0.020149 
[286]	train-rmse:0.211921+0.003027	test-rmse:0.225726+0.020149 
[287]	train-rmse:0.211405+0.002709	test-rmse:0.225552+0.020232 
[288]	train-rmse:0.211220+0.003045	test-rmse:0.225480+0.020243 
[289]	train-rmse:0.211222+0.003044	test-rmse:0.225482+0.020242 
[290]	train-rmse:0.210820+0.003129	test-rmse:0.225244+0.019939 
[291]	train-rmse:0.210823+0.003129	test-rmse:0.225244+0.019937 
[292]	train-rmse:0.210826+0.003129	test-rmse:0.225246+0.019936 
[293]	train-rmse:0.210830+0.003129	test-rmse:0.225246+0.019937 
[294]	train-rmse:0.210584+0.003280	test-rmse:0.225156+0.019825 
[295]	train-rmse:0.210280+0.003555	test-rmse:0.225119+0.019779 
[296]	train-rmse:0.210282+0.003555	test-rmse:0.225119+0.019778 
[297]	train-rmse:0.209948+0.003550	test-rmse:0.224822+0.019467 
[298]	train-rmse:0.209952+0.003550	test-rmse:0.224822+0.019466 
[299]	train-rmse:0.209807+0.003733	test-rmse:0.224681+0.019484 
[300]	train-rmse:0.209525+0.003656	test-rmse:0.224448+0.019713 
[301]	train-rmse:0.209528+0.003655	test-rmse:0.224449+0.019712 
[302]	train-rmse:0.209317+0.003497	test-rmse:0.224414+0.019750 
[303]	train-rmse:0.209320+0.003497	test-rmse:0.224416+0.019749 
[304]	train-rmse:0.209323+0.003497	test-rmse:0.224418+0.019749 
[305]	train-rmse:0.209325+0.003497	test-rmse:0.224418+0.019748 
[306]	train-rmse:0.209171+0.003628	test-rmse:0.224507+0.019862 
[307]	train-rmse:0.209174+0.003628	test-rmse:0.224506+0.019862 
[308]	train-rmse:0.209177+0.003628	test-rmse:0.224507+0.019860 
[309]	train-rmse:0.209180+0.003629	test-rmse:0.224508+0.019860 
[310]	train-rmse:0.209183+0.003628	test-rmse:0.224509+0.019859 
[311]	train-rmse:0.209186+0.003628	test-rmse:0.224508+0.019857 
[312]	train-rmse:0.208979+0.003838	test-rmse:0.224500+0.019846 
[313]	train-rmse:0.208833+0.004007	test-rmse:0.224657+0.020046 
[314]	train-rmse:0.208836+0.004007	test-rmse:0.224659+0.020046 
[315]	train-rmse:0.208838+0.004007	test-rmse:0.224659+0.020045 
[316]	train-rmse:0.208632+0.004268	test-rmse:0.224660+0.020045 
[317]	train-rmse:0.208635+0.004268	test-rmse:0.224663+0.020045 
[318]	train-rmse:0.208534+0.004368	test-rmse:0.224748+0.020033 
[319]	train-rmse:0.208537+0.004368	test-rmse:0.224750+0.020031 
[320]	train-rmse:0.208403+0.004184	test-rmse:0.224622+0.020177 
[321]	train-rmse:0.208405+0.004183	test-rmse:0.224623+0.020176 
[322]	train-rmse:0.208408+0.004183	test-rmse:0.224622+0.020177 
[323]	train-rmse:0.208411+0.004183	test-rmse:0.224623+0.020176 
[324]	train-rmse:0.208414+0.004183	test-rmse:0.224625+0.020176 
[325]	train-rmse:0.208254+0.003978	test-rmse:0.224464+0.020362 
[326]	train-rmse:0.208165+0.004075	test-rmse:0.224452+0.020365 
[327]	train-rmse:0.208064+0.003993	test-rmse:0.224236+0.020585 
[328]	train-rmse:0.208067+0.003992	test-rmse:0.224237+0.020584 
[329]	train-rmse:0.208070+0.003992	test-rmse:0.224239+0.020583 
[330]	train-rmse:0.208072+0.003991	test-rmse:0.224240+0.020583 
[331]	train-rmse:0.207934+0.004172	test-rmse:0.224329+0.020696 
[332]	train-rmse:0.207669+0.004111	test-rmse:0.224283+0.020650 
[333]	train-rmse:0.207671+0.004110	test-rmse:0.224285+0.020650 
[334]	train-rmse:0.207499+0.004343	test-rmse:0.224224+0.020572 
[335]	train-rmse:0.207417+0.004419	test-rmse:0.224016+0.020596 
[336]	train-rmse:0.207274+0.004238	test-rmse:0.223849+0.020787 
[337]	train-rmse:0.207277+0.004239	test-rmse:0.223850+0.020786 
[338]	train-rmse:0.207280+0.004239	test-rmse:0.223852+0.020785 
[339]	train-rmse:0.207178+0.004149	test-rmse:0.223846+0.020791 
[340]	train-rmse:0.207181+0.004149	test-rmse:0.223846+0.020791 
[341]	train-rmse:0.207183+0.004148	test-rmse:0.223848+0.020791 
[342]	train-rmse:0.207185+0.004148	test-rmse:0.223849+0.020792 
[343]	train-rmse:0.207188+0.004148	test-rmse:0.223850+0.020792 
[344]	train-rmse:0.207191+0.004148	test-rmse:0.223851+0.020792 
[345]	train-rmse:0.207094+0.004026	test-rmse:0.223686+0.020984 
[346]	train-rmse:0.207096+0.004025	test-rmse:0.223685+0.020984 
[347]	train-rmse:0.207099+0.004024	test-rmse:0.223686+0.020985 
[348]	train-rmse:0.207101+0.004024	test-rmse:0.223687+0.020985 
[349]	train-rmse:0.206892+0.003993	test-rmse:0.223750+0.021047 
[350]	train-rmse:0.206894+0.003993	test-rmse:0.223751+0.021046 
[351]	train-rmse:0.206897+0.003993	test-rmse:0.223752+0.021045 
[352]	train-rmse:0.206729+0.003846	test-rmse:0.223935+0.020866 
[353]	train-rmse:0.206731+0.003846	test-rmse:0.223937+0.020865 
[354]	train-rmse:0.206663+0.003910	test-rmse:0.223919+0.020867 
[355]	train-rmse:0.206667+0.003910	test-rmse:0.223920+0.020867 
[356]	train-rmse:0.206669+0.003910	test-rmse:0.223921+0.020867 
[357]	train-rmse:0.206356+0.004264	test-rmse:0.223683+0.020723 
[358]	train-rmse:0.206359+0.004263	test-rmse:0.223684+0.020722 
[359]	train-rmse:0.206361+0.004262	test-rmse:0.223684+0.020722 
[360]	train-rmse:0.206363+0.004262	test-rmse:0.223685+0.020722 
[361]	train-rmse:0.206055+0.004151	test-rmse:0.223401+0.020941 
[362]	train-rmse:0.205504+0.004196	test-rmse:0.223391+0.020866 
[363]	train-rmse:0.205382+0.004095	test-rmse:0.223469+0.020792 
[364]	train-rmse:0.205384+0.004095	test-rmse:0.223469+0.020792 
[365]	train-rmse:0.205386+0.004094	test-rmse:0.223470+0.020792 
[366]	train-rmse:0.205389+0.004095	test-rmse:0.223471+0.020793 
[367]	train-rmse:0.205317+0.004010	test-rmse:0.223562+0.020685 
[368]	train-rmse:0.205219+0.003901	test-rmse:0.223523+0.020732 
[369]	train-rmse:0.205221+0.003901	test-rmse:0.223524+0.020730 
[370]	train-rmse:0.205224+0.003902	test-rmse:0.223524+0.020730 
[371]	train-rmse:0.205110+0.003809	test-rmse:0.223353+0.020897 
[372]	train-rmse:0.205113+0.003809	test-rmse:0.223354+0.020897 
[373]	train-rmse:0.205116+0.003809	test-rmse:0.223355+0.020897 
[374]	train-rmse:0.205119+0.003809	test-rmse:0.223356+0.020898 
[375]	train-rmse:0.205122+0.003809	test-rmse:0.223356+0.020898 
[376]	train-rmse:0.205125+0.003808	test-rmse:0.223357+0.020897 
[377]	train-rmse:0.205127+0.003808	test-rmse:0.223357+0.020896 
[378]	train-rmse:0.205130+0.003808	test-rmse:0.223358+0.020895 
[379]	train-rmse:0.204945+0.004088	test-rmse:0.223351+0.020885 
[380]	train-rmse:0.204948+0.004088	test-rmse:0.223351+0.020885 
[381]	train-rmse:0.204741+0.003997	test-rmse:0.223285+0.020816 
[382]	train-rmse:0.204616+0.003900	test-rmse:0.223158+0.020944 
[383]	train-rmse:0.204618+0.003900	test-rmse:0.223157+0.020944 
[384]	train-rmse:0.204621+0.003900	test-rmse:0.223158+0.020944 
[385]	train-rmse:0.204412+0.003682	test-rmse:0.223062+0.021068 
[386]	train-rmse:0.204414+0.003682	test-rmse:0.223061+0.021067 
[387]	train-rmse:0.204416+0.003681	test-rmse:0.223061+0.021067 
[388]	train-rmse:0.204418+0.003681	test-rmse:0.223062+0.021067 
[389]	train-rmse:0.204191+0.003691	test-rmse:0.222930+0.021129 
[390]	train-rmse:0.204130+0.003748	test-rmse:0.222856+0.021141 
[391]	train-rmse:0.204132+0.003748	test-rmse:0.222856+0.021142 
[392]	train-rmse:0.204134+0.003748	test-rmse:0.222858+0.021141 
[393]	train-rmse:0.203903+0.003652	test-rmse:0.222795+0.021078 
> hgrid <-
+   dplyr::bind_cols(xgboost_params[index, ], dart.cv$evaluation_log[dart.cv$best_iteration, ], best_iter = dart.cv$best_iteration)
> 
> # write result
> fname <- file.path('data-raw', 'tune', year, 'array', paste0('tune_', index, '.tsv'))
> readr::write_tsv(hgrid, file = fname)
> 
