> 
> # parse arguments
> args <- R.utils::commandArgs(trailingOnly = FALSE, asValues = TRUE)
> index <- as.integer(args$index)
> year <- as.character(args$year)
> nreps <- as.integer(args$nreps)
> seed <- as.integer(args$seed)
> 
> # get number of cores
> wkrs <- length(future::availableWorkers())
> 
> # set seed
> set.seed(seed)
> 
> # read and prepare the cluster features
> fp <- file.path('data-raw', 'features', year)
> clf <-
+   read_features(fp, pattern = 'paris.', recursive = FALSE)
> clf <- prepare_features(
+   clf,
+   feature_map = feature_map,
+   category = c('response', 'bio', 'net'),
+   type = 'list',
+   exclusions = c(
+     'mg2_pairs_count',
+     'mg2_not_pairs_count',
+     'mg2_portion_families_recovered',
+     'cluster_origin',
+     'bocc_origin',
+     'cluster_method',
+     'subcluster_method',
+     'year',
+     'IDs',
+     'go_sig_threshold',
+     'num_new_edges_on_any_node',
+     'HPO_ratio'
+   ),
+   verbose = TRUE
+ )
c('HPO_ratio', 'IDs', 'bocc_origin', 'cluster_method', 'cluster_origin', 'go_sig_threshold', 'max_norm_cell_type_comma_sep_string', 'max_norm_disease_comma_sep_string', 'mg2_not_pairs_count', 'mg2_pairs_count', 'mg2_portion_families_recovered', 'num_new_edges_on_any_node', 'sig_go_enrichment_fdr_corrected_p_vals', 'sig_go_enrichment_p_vals', 'sig_go_enrichment_terms', 'subcluster_method', 'year')

> 
> # prepare grid of parameters
> xgboost_params <- dials::parameters(
+   nrounds = dials::trees(),
+   eta = dials::learn_rate(),
+   gamma = dials::loss_reduction(),
+   dials::tree_depth(),
+   subsample = dials::sample_prop(),
+   rate_drop = dials::dropout(),
+   skip_drop = dials::dropout()
+ )
> xgboost_params <-
+   dials::grid_max_entropy(xgboost_params, size = nreps)
> 
> # tune the dart booster
> dart.param <-
+   list(
+     booster = "dart",
+     objective = "reg:logistic",
+     eval_metric = "rmse",
+     nthread = wkrs,
+     max_depth = xgboost_params$tree_depth[index],
+     eta = xgboost_params$eta[index],
+     gamma = xgboost_params$gamma[index],
+     subsample = xgboost_params$subsample[index],
+     rate_drop = xgboost_params$rate_drop[index],
+     skip_drop = xgboost_params$skip_drop[index]
+   )
> dart.cv <- xgboost::xgb.cv(
+   params = dart.param,
+   nrounds = xgboost_params$nrounds[index],
+   data = as.matrix(clf[, -1]),
+   nfold = 5,
+   label = clf$snowballing_pvalue,
+   early_stopping_rounds = 50
+ )
[1]	train-rmse:0.376546+0.000989	test-rmse:0.377246+0.004190 
Multiple eval metrics are present. Will use test_rmse for early stopping.
Will train until test_rmse hasn't improved in 50 rounds.

[2]	train-rmse:0.370656+0.000957	test-rmse:0.371958+0.004150 
[3]	train-rmse:0.364869+0.000884	test-rmse:0.366803+0.004145 
[4]	train-rmse:0.359720+0.000483	test-rmse:0.362252+0.005082 
[5]	train-rmse:0.355476+0.001560	test-rmse:0.358466+0.004690 
[6]	train-rmse:0.353866+0.001844	test-rmse:0.357063+0.004779 
[7]	train-rmse:0.348972+0.002393	test-rmse:0.352718+0.004666 
[8]	train-rmse:0.347047+0.002311	test-rmse:0.351000+0.004799 
[9]	train-rmse:0.343453+0.002636	test-rmse:0.347879+0.003549 
[10]	train-rmse:0.339973+0.004456	test-rmse:0.344795+0.003293 
[11]	train-rmse:0.338372+0.005302	test-rmse:0.343331+0.002231 
[12]	train-rmse:0.336728+0.004528	test-rmse:0.341882+0.002961 
[13]	train-rmse:0.332537+0.004933	test-rmse:0.338315+0.003109 
[14]	train-rmse:0.329280+0.006186	test-rmse:0.335503+0.002991 
[15]	train-rmse:0.327633+0.005683	test-rmse:0.334062+0.003761 
[16]	train-rmse:0.322697+0.005540	test-rmse:0.329848+0.003708 
[17]	train-rmse:0.319525+0.003660	test-rmse:0.327200+0.003747 
[18]	train-rmse:0.317393+0.004567	test-rmse:0.325432+0.003141 
[19]	train-rmse:0.314391+0.003574	test-rmse:0.322817+0.003781 
[20]	train-rmse:0.310602+0.004272	test-rmse:0.319531+0.004398 
[21]	train-rmse:0.307677+0.003487	test-rmse:0.317052+0.003076 
[22]	train-rmse:0.304848+0.003446	test-rmse:0.314705+0.004418 
[23]	train-rmse:0.301210+0.002911	test-rmse:0.311717+0.005161 
[24]	train-rmse:0.297652+0.002700	test-rmse:0.308810+0.004226 
[25]	train-rmse:0.296604+0.004055	test-rmse:0.307989+0.004564 
[26]	train-rmse:0.293162+0.005128	test-rmse:0.305098+0.005399 
[27]	train-rmse:0.289749+0.003889	test-rmse:0.302263+0.005074 
[28]	train-rmse:0.287225+0.005293	test-rmse:0.300088+0.005773 
[29]	train-rmse:0.285425+0.004296	test-rmse:0.298648+0.005793 
[30]	train-rmse:0.284447+0.003998	test-rmse:0.297846+0.005968 
[31]	train-rmse:0.282738+0.005038	test-rmse:0.296466+0.006555 
[32]	train-rmse:0.280296+0.006352	test-rmse:0.294451+0.006838 
[33]	train-rmse:0.277798+0.005023	test-rmse:0.292470+0.006110 
[34]	train-rmse:0.276181+0.005855	test-rmse:0.291114+0.006370 
[35]	train-rmse:0.274586+0.006963	test-rmse:0.289827+0.007124 
[36]	train-rmse:0.272938+0.006338	test-rmse:0.288578+0.006418 
[37]	train-rmse:0.270616+0.007090	test-rmse:0.286705+0.006926 
[38]	train-rmse:0.266881+0.006910	test-rmse:0.283773+0.006932 
[39]	train-rmse:0.265393+0.008081	test-rmse:0.282616+0.007736 
[40]	train-rmse:0.263193+0.008242	test-rmse:0.280965+0.007744 
[41]	train-rmse:0.262408+0.008781	test-rmse:0.280360+0.008277 
[42]	train-rmse:0.260158+0.007954	test-rmse:0.278657+0.008256 
[43]	train-rmse:0.257246+0.007082	test-rmse:0.276395+0.007941 
[44]	train-rmse:0.255819+0.007839	test-rmse:0.275260+0.008238 
[45]	train-rmse:0.253046+0.007837	test-rmse:0.273145+0.008457 
[46]	train-rmse:0.251727+0.009226	test-rmse:0.272189+0.009226 
[47]	train-rmse:0.249076+0.009526	test-rmse:0.270267+0.008965 
[48]	train-rmse:0.246978+0.007936	test-rmse:0.268754+0.008096 
[49]	train-rmse:0.244978+0.007600	test-rmse:0.267311+0.007285 
[50]	train-rmse:0.244299+0.008219	test-rmse:0.266809+0.007543 
[51]	train-rmse:0.241665+0.007420	test-rmse:0.264847+0.006905 
[52]	train-rmse:0.239697+0.006727	test-rmse:0.263427+0.006898 
[53]	train-rmse:0.237191+0.006954	test-rmse:0.261656+0.007325 
[54]	train-rmse:0.234755+0.007405	test-rmse:0.259926+0.007800 
[55]	train-rmse:0.233594+0.008734	test-rmse:0.259137+0.008502 
[56]	train-rmse:0.232371+0.008870	test-rmse:0.258255+0.008463 
[57]	train-rmse:0.231146+0.009126	test-rmse:0.257445+0.008266 
[58]	train-rmse:0.228735+0.008314	test-rmse:0.255694+0.007678 
[59]	train-rmse:0.227547+0.008593	test-rmse:0.254799+0.007546 
[60]	train-rmse:0.225749+0.008138	test-rmse:0.253551+0.007553 
[61]	train-rmse:0.224586+0.008526	test-rmse:0.252787+0.007540 
[62]	train-rmse:0.224540+0.008522	test-rmse:0.252752+0.007538 
[63]	train-rmse:0.223307+0.007276	test-rmse:0.251835+0.007186 
[64]	train-rmse:0.221650+0.007978	test-rmse:0.250670+0.008044 
[65]	train-rmse:0.219370+0.007235	test-rmse:0.249113+0.007784 
[66]	train-rmse:0.217719+0.007145	test-rmse:0.248016+0.007298 
[67]	train-rmse:0.216585+0.006561	test-rmse:0.247260+0.006492 
[68]	train-rmse:0.215454+0.005853	test-rmse:0.246530+0.006357 
[69]	train-rmse:0.214357+0.005531	test-rmse:0.245795+0.005571 
[70]	train-rmse:0.212760+0.005704	test-rmse:0.244756+0.004890 
[71]	train-rmse:0.211736+0.006572	test-rmse:0.244109+0.005067 
[72]	train-rmse:0.210659+0.006183	test-rmse:0.243436+0.004995 
[73]	train-rmse:0.209606+0.005627	test-rmse:0.242715+0.005329 
[74]	train-rmse:0.208115+0.005876	test-rmse:0.241751+0.004655 
[75]	train-rmse:0.207110+0.005520	test-rmse:0.241069+0.005339 
[76]	train-rmse:0.205130+0.005282	test-rmse:0.239802+0.005368 
[77]	train-rmse:0.203696+0.005850	test-rmse:0.238864+0.005115 
[78]	train-rmse:0.201815+0.006171	test-rmse:0.237671+0.005506 
[79]	train-rmse:0.200840+0.005650	test-rmse:0.237006+0.005816 
[80]	train-rmse:0.199878+0.005208	test-rmse:0.236332+0.005466 
[81]	train-rmse:0.198016+0.004751	test-rmse:0.235103+0.005265 
[82]	train-rmse:0.196190+0.004487	test-rmse:0.233938+0.005160 
[83]	train-rmse:0.195297+0.004310	test-rmse:0.233353+0.005654 
[84]	train-rmse:0.193926+0.004544	test-rmse:0.232596+0.005932 
[85]	train-rmse:0.192565+0.003695	test-rmse:0.231719+0.006178 
[86]	train-rmse:0.191693+0.003280	test-rmse:0.231141+0.005984 
[87]	train-rmse:0.189950+0.002820	test-rmse:0.230035+0.006381 
[88]	train-rmse:0.188667+0.002962	test-rmse:0.229310+0.006047 
[89]	train-rmse:0.187007+0.003418	test-rmse:0.228385+0.006288 
[90]	train-rmse:0.185343+0.003194	test-rmse:0.227507+0.006355 
[91]	train-rmse:0.183741+0.003210	test-rmse:0.226625+0.006490 
[92]	train-rmse:0.182116+0.002841	test-rmse:0.225707+0.006419 
[93]	train-rmse:0.180940+0.003450	test-rmse:0.225069+0.006625 
[94]	train-rmse:0.180926+0.003450	test-rmse:0.225059+0.006627 
[95]	train-rmse:0.179377+0.003232	test-rmse:0.224232+0.006588 
[96]	train-rmse:0.178596+0.002983	test-rmse:0.223810+0.006572 
[97]	train-rmse:0.178209+0.003616	test-rmse:0.223621+0.006297 
[98]	train-rmse:0.177840+0.004253	test-rmse:0.223445+0.006049 
[99]	train-rmse:0.175980+0.004188	test-rmse:0.222430+0.006162 
[100]	train-rmse:0.174870+0.004394	test-rmse:0.221816+0.006195 
[101]	train-rmse:0.173063+0.004337	test-rmse:0.220789+0.006313 
[102]	train-rmse:0.171969+0.004066	test-rmse:0.220203+0.006677 
[103]	train-rmse:0.170544+0.003460	test-rmse:0.219450+0.006904 
[104]	train-rmse:0.170179+0.003468	test-rmse:0.219235+0.007235 
[105]	train-rmse:0.169498+0.003862	test-rmse:0.218912+0.007018 
[106]	train-rmse:0.168480+0.004401	test-rmse:0.218377+0.007155 
[107]	train-rmse:0.167129+0.004312	test-rmse:0.217651+0.006941 
[108]	train-rmse:0.166132+0.004798	test-rmse:0.217177+0.007151 
[109]	train-rmse:0.165132+0.004252	test-rmse:0.216601+0.007367 
[110]	train-rmse:0.164174+0.004268	test-rmse:0.216151+0.007143 
[111]	train-rmse:0.163545+0.004392	test-rmse:0.215915+0.006947 
[112]	train-rmse:0.162576+0.004008	test-rmse:0.215414+0.007179 
[113]	train-rmse:0.161609+0.003468	test-rmse:0.214907+0.007183 
[114]	train-rmse:0.161281+0.003281	test-rmse:0.214763+0.007206 
[115]	train-rmse:0.160027+0.003410	test-rmse:0.214147+0.007283 
[116]	train-rmse:0.159110+0.003973	test-rmse:0.213664+0.007364 
[117]	train-rmse:0.158503+0.004238	test-rmse:0.213387+0.007201 
[118]	train-rmse:0.157596+0.003799	test-rmse:0.212961+0.007210 
[119]	train-rmse:0.157014+0.004176	test-rmse:0.212717+0.007059 
[120]	train-rmse:0.156168+0.004688	test-rmse:0.212346+0.006940 
[121]	train-rmse:0.155883+0.005176	test-rmse:0.212275+0.006830 
[122]	train-rmse:0.154740+0.005483	test-rmse:0.211782+0.006972 
[123]	train-rmse:0.153616+0.005814	test-rmse:0.211293+0.007121 
[124]	train-rmse:0.153051+0.005708	test-rmse:0.211029+0.007367 
[125]	train-rmse:0.152241+0.006063	test-rmse:0.210665+0.007520 
[126]	train-rmse:0.151634+0.005659	test-rmse:0.210360+0.007482 
[127]	train-rmse:0.150812+0.005700	test-rmse:0.210043+0.007377 
[128]	train-rmse:0.149741+0.006021	test-rmse:0.209586+0.007501 
[129]	train-rmse:0.148695+0.006382	test-rmse:0.209143+0.007682 
[130]	train-rmse:0.148443+0.006533	test-rmse:0.209041+0.007724 
[131]	train-rmse:0.147925+0.006690	test-rmse:0.208839+0.007788 
[132]	train-rmse:0.146842+0.006404	test-rmse:0.208414+0.007862 
[133]	train-rmse:0.146272+0.005831	test-rmse:0.208103+0.007995 
[134]	train-rmse:0.145210+0.005580	test-rmse:0.207653+0.008067 
[135]	train-rmse:0.144484+0.005975	test-rmse:0.207394+0.008107 
[136]	train-rmse:0.144221+0.005954	test-rmse:0.207266+0.008298 
[137]	train-rmse:0.143183+0.005528	test-rmse:0.206835+0.008432 
[138]	train-rmse:0.142233+0.005925	test-rmse:0.206481+0.008560 
[139]	train-rmse:0.141511+0.006231	test-rmse:0.206241+0.008695 
[140]	train-rmse:0.141054+0.006567	test-rmse:0.206110+0.008739 
[141]	train-rmse:0.140829+0.006641	test-rmse:0.206013+0.008767 
[142]	train-rmse:0.140107+0.006490	test-rmse:0.205728+0.008759 
[143]	train-rmse:0.139403+0.006822	test-rmse:0.205507+0.008712 
[144]	train-rmse:0.138503+0.007200	test-rmse:0.205224+0.008833 
[145]	train-rmse:0.137559+0.007046	test-rmse:0.204871+0.008730 
[146]	train-rmse:0.136839+0.006591	test-rmse:0.204555+0.008803 
[147]	train-rmse:0.136189+0.006706	test-rmse:0.204338+0.008955 
[148]	train-rmse:0.135750+0.006785	test-rmse:0.204175+0.009111 
[149]	train-rmse:0.135521+0.006832	test-rmse:0.204115+0.009123 
[150]	train-rmse:0.134670+0.006701	test-rmse:0.203778+0.009110 
[151]	train-rmse:0.134233+0.006822	test-rmse:0.203675+0.009184 
[152]	train-rmse:0.133639+0.007161	test-rmse:0.203463+0.009233 
[153]	train-rmse:0.132975+0.006991	test-rmse:0.203290+0.009290 
[154]	train-rmse:0.132373+0.007320	test-rmse:0.203106+0.009303 
[155]	train-rmse:0.131916+0.006976	test-rmse:0.202915+0.009360 
[156]	train-rmse:0.131297+0.006913	test-rmse:0.202688+0.009318 
[157]	train-rmse:0.130664+0.006604	test-rmse:0.202441+0.009395 
[158]	train-rmse:0.129828+0.006351	test-rmse:0.202132+0.009296 
[159]	train-rmse:0.129257+0.006472	test-rmse:0.201912+0.009412 
[160]	train-rmse:0.128473+0.006212	test-rmse:0.201656+0.009504 
[161]	train-rmse:0.127882+0.005899	test-rmse:0.201429+0.009560 
[162]	train-rmse:0.127263+0.005661	test-rmse:0.201173+0.009650 
[163]	train-rmse:0.126650+0.005258	test-rmse:0.200965+0.009650 
[164]	train-rmse:0.125865+0.005015	test-rmse:0.200771+0.009591 
[165]	train-rmse:0.125276+0.004748	test-rmse:0.200568+0.009689 
[166]	train-rmse:0.124879+0.004360	test-rmse:0.200420+0.009689 
[167]	train-rmse:0.124711+0.004501	test-rmse:0.200377+0.009617 
[168]	train-rmse:0.123785+0.004450	test-rmse:0.200145+0.009679 
[169]	train-rmse:0.123065+0.004386	test-rmse:0.199933+0.009708 
[170]	train-rmse:0.122534+0.004175	test-rmse:0.199745+0.009791 
[171]	train-rmse:0.121802+0.003980	test-rmse:0.199553+0.009740 
[172]	train-rmse:0.121450+0.004023	test-rmse:0.199465+0.009756 
[173]	train-rmse:0.121082+0.003693	test-rmse:0.199354+0.009766 
[174]	train-rmse:0.120748+0.003848	test-rmse:0.199273+0.009725 
[175]	train-rmse:0.120235+0.004130	test-rmse:0.199112+0.009746 
[176]	train-rmse:0.119743+0.004424	test-rmse:0.198974+0.009732 
[177]	train-rmse:0.119373+0.004077	test-rmse:0.198880+0.009741 
[178]	train-rmse:0.118727+0.004383	test-rmse:0.198736+0.009736 
[179]	train-rmse:0.118265+0.004611	test-rmse:0.198611+0.009687 
[180]	train-rmse:0.118114+0.004690	test-rmse:0.198572+0.009742 
[181]	train-rmse:0.117616+0.004534	test-rmse:0.198445+0.009759 
[182]	train-rmse:0.117104+0.004217	test-rmse:0.198303+0.009773 
[183]	train-rmse:0.116801+0.004454	test-rmse:0.198229+0.009764 
[184]	train-rmse:0.116500+0.004512	test-rmse:0.198150+0.009778 
[185]	train-rmse:0.116045+0.004684	test-rmse:0.198039+0.009847 
[186]	train-rmse:0.115403+0.004530	test-rmse:0.197898+0.009791 
[187]	train-rmse:0.114973+0.004767	test-rmse:0.197802+0.009814 
[188]	train-rmse:0.114493+0.004611	test-rmse:0.197711+0.009867 
[189]	train-rmse:0.114020+0.004395	test-rmse:0.197612+0.009898 
[190]	train-rmse:0.113448+0.004664	test-rmse:0.197499+0.009938 
[191]	train-rmse:0.112985+0.004567	test-rmse:0.197418+0.009918 
[192]	train-rmse:0.112528+0.004411	test-rmse:0.197322+0.009894 
[193]	train-rmse:0.111959+0.004255	test-rmse:0.197136+0.009982 
[194]	train-rmse:0.111383+0.004200	test-rmse:0.197005+0.010003 
[195]	train-rmse:0.111113+0.004374	test-rmse:0.196945+0.009985 
[196]	train-rmse:0.110690+0.004099	test-rmse:0.196799+0.010001 
[197]	train-rmse:0.110280+0.004371	test-rmse:0.196718+0.010030 
[198]	train-rmse:0.109872+0.004566	test-rmse:0.196641+0.010046 
[199]	train-rmse:0.109875+0.004566	test-rmse:0.196641+0.010046 
[200]	train-rmse:0.109723+0.004276	test-rmse:0.196606+0.010049 
[201]	train-rmse:0.109037+0.004227	test-rmse:0.196416+0.010094 
[202]	train-rmse:0.108614+0.004003	test-rmse:0.196310+0.010148 
[203]	train-rmse:0.108058+0.003986	test-rmse:0.196225+0.010125 
[204]	train-rmse:0.107660+0.003866	test-rmse:0.196111+0.010183 
[205]	train-rmse:0.107539+0.003922	test-rmse:0.196080+0.010191 
[206]	train-rmse:0.107279+0.003785	test-rmse:0.195992+0.010236 
[207]	train-rmse:0.106865+0.003767	test-rmse:0.195936+0.010227 
[208]	train-rmse:0.106321+0.003682	test-rmse:0.195847+0.010256 
[209]	train-rmse:0.105941+0.003771	test-rmse:0.195773+0.010219 
[210]	train-rmse:0.105552+0.003890	test-rmse:0.195726+0.010229 
[211]	train-rmse:0.105046+0.003812	test-rmse:0.195607+0.010246 
[212]	train-rmse:0.104934+0.003910	test-rmse:0.195584+0.010277 
[213]	train-rmse:0.104569+0.003661	test-rmse:0.195506+0.010286 
[214]	train-rmse:0.104572+0.003660	test-rmse:0.195506+0.010286 
[215]	train-rmse:0.104190+0.003567	test-rmse:0.195413+0.010283 
[216]	train-rmse:0.103827+0.003485	test-rmse:0.195358+0.010319 
[217]	train-rmse:0.103580+0.003346	test-rmse:0.195294+0.010360 
[218]	train-rmse:0.103096+0.003322	test-rmse:0.195196+0.010359 
[219]	train-rmse:0.102858+0.003062	test-rmse:0.195129+0.010373 
[220]	train-rmse:0.102532+0.003213	test-rmse:0.195109+0.010365 
[221]	train-rmse:0.102169+0.002977	test-rmse:0.195033+0.010377 
[222]	train-rmse:0.101687+0.002822	test-rmse:0.194972+0.010368 
[223]	train-rmse:0.101474+0.002740	test-rmse:0.194919+0.010396 
[224]	train-rmse:0.101107+0.002660	test-rmse:0.194831+0.010397 
[225]	train-rmse:0.100527+0.002627	test-rmse:0.194771+0.010421 
[226]	train-rmse:0.100295+0.002371	test-rmse:0.194739+0.010428 
[227]	train-rmse:0.100062+0.002288	test-rmse:0.194721+0.010436 
[228]	train-rmse:0.099606+0.002268	test-rmse:0.194659+0.010417 
[229]	train-rmse:0.099287+0.002206	test-rmse:0.194603+0.010427 
[230]	train-rmse:0.098839+0.002364	test-rmse:0.194564+0.010487 
[231]	train-rmse:0.098618+0.002345	test-rmse:0.194542+0.010484 
[232]	train-rmse:0.098394+0.002381	test-rmse:0.194537+0.010499 
[233]	train-rmse:0.098301+0.002363	test-rmse:0.194534+0.010500 
[234]	train-rmse:0.097880+0.002513	test-rmse:0.194527+0.010538 
[235]	train-rmse:0.097459+0.002487	test-rmse:0.194463+0.010553 
[236]	train-rmse:0.097259+0.002565	test-rmse:0.194430+0.010575 
[237]	train-rmse:0.096934+0.002461	test-rmse:0.194370+0.010567 
[238]	train-rmse:0.096748+0.002571	test-rmse:0.194371+0.010582 
[239]	train-rmse:0.096569+0.002645	test-rmse:0.194358+0.010582 
[240]	train-rmse:0.096285+0.002796	test-rmse:0.194306+0.010580 
[241]	train-rmse:0.095973+0.002666	test-rmse:0.194241+0.010600 
[242]	train-rmse:0.095459+0.002649	test-rmse:0.194150+0.010606 
[243]	train-rmse:0.095256+0.002744	test-rmse:0.194123+0.010593 
[244]	train-rmse:0.094960+0.002808	test-rmse:0.194133+0.010584 
[245]	train-rmse:0.094661+0.002857	test-rmse:0.194092+0.010586 
[246]	train-rmse:0.094554+0.002690	test-rmse:0.194055+0.010599 
[247]	train-rmse:0.094335+0.002489	test-rmse:0.194002+0.010607 
[248]	train-rmse:0.094045+0.002279	test-rmse:0.193954+0.010618 
[249]	train-rmse:0.093956+0.002353	test-rmse:0.193948+0.010626 
[250]	train-rmse:0.093564+0.002501	test-rmse:0.193948+0.010640 
[251]	train-rmse:0.093189+0.002427	test-rmse:0.193863+0.010643 
[252]	train-rmse:0.093019+0.002605	test-rmse:0.193854+0.010616 
[253]	train-rmse:0.092917+0.002446	test-rmse:0.193861+0.010613 
[254]	train-rmse:0.092921+0.002446	test-rmse:0.193861+0.010613 
[255]	train-rmse:0.092631+0.002353	test-rmse:0.193820+0.010631 
[256]	train-rmse:0.092461+0.002446	test-rmse:0.193823+0.010634 
[257]	train-rmse:0.092273+0.002286	test-rmse:0.193805+0.010627 
[258]	train-rmse:0.091893+0.002280	test-rmse:0.193769+0.010628 
[259]	train-rmse:0.091795+0.002257	test-rmse:0.193752+0.010628 
[260]	train-rmse:0.091695+0.002208	test-rmse:0.193754+0.010627 
[261]	train-rmse:0.091430+0.002161	test-rmse:0.193690+0.010611 
[262]	train-rmse:0.091057+0.002306	test-rmse:0.193675+0.010636 
[263]	train-rmse:0.090784+0.002478	test-rmse:0.193679+0.010661 
[264]	train-rmse:0.090446+0.002479	test-rmse:0.193615+0.010711 
[265]	train-rmse:0.090273+0.002483	test-rmse:0.193600+0.010720 
[266]	train-rmse:0.089920+0.002507	test-rmse:0.193567+0.010738 
[267]	train-rmse:0.089748+0.002360	test-rmse:0.193576+0.010738 
[268]	train-rmse:0.089659+0.002309	test-rmse:0.193587+0.010736 
[269]	train-rmse:0.089485+0.002413	test-rmse:0.193567+0.010759 
[270]	train-rmse:0.089149+0.002358	test-rmse:0.193523+0.010723 
[271]	train-rmse:0.088887+0.002345	test-rmse:0.193502+0.010755 
[272]	train-rmse:0.088548+0.002356	test-rmse:0.193500+0.010726 
[273]	train-rmse:0.088456+0.002392	test-rmse:0.193492+0.010736 
[274]	train-rmse:0.088209+0.002357	test-rmse:0.193474+0.010744 
[275]	train-rmse:0.087958+0.002314	test-rmse:0.193437+0.010767 
[276]	train-rmse:0.087889+0.002436	test-rmse:0.193446+0.010783 
[277]	train-rmse:0.087554+0.002391	test-rmse:0.193434+0.010807 
[278]	train-rmse:0.087215+0.002240	test-rmse:0.193408+0.010830 
[279]	train-rmse:0.086979+0.002133	test-rmse:0.193399+0.010824 
[280]	train-rmse:0.086658+0.002147	test-rmse:0.193391+0.010877 
[281]	train-rmse:0.086661+0.002147	test-rmse:0.193391+0.010876 
[282]	train-rmse:0.086420+0.002275	test-rmse:0.193365+0.010920 
[283]	train-rmse:0.086099+0.002236	test-rmse:0.193335+0.010884 
[284]	train-rmse:0.085802+0.002260	test-rmse:0.193303+0.010870 
[285]	train-rmse:0.085668+0.002133	test-rmse:0.193291+0.010874 
[286]	train-rmse:0.085441+0.002190	test-rmse:0.193303+0.010888 
[287]	train-rmse:0.085162+0.002209	test-rmse:0.193310+0.010915 
[288]	train-rmse:0.084985+0.002316	test-rmse:0.193292+0.010908 
[289]	train-rmse:0.084733+0.002438	test-rmse:0.193272+0.010914 
[290]	train-rmse:0.084737+0.002438	test-rmse:0.193272+0.010913 
[291]	train-rmse:0.084503+0.002335	test-rmse:0.193252+0.010915 
[292]	train-rmse:0.084359+0.002334	test-rmse:0.193252+0.010921 
[293]	train-rmse:0.084136+0.002461	test-rmse:0.193250+0.010933 
[294]	train-rmse:0.083983+0.002564	test-rmse:0.193261+0.010945 
[295]	train-rmse:0.083725+0.002635	test-rmse:0.193258+0.010931 
[296]	train-rmse:0.083425+0.002598	test-rmse:0.193262+0.010964 
[297]	train-rmse:0.083154+0.002649	test-rmse:0.193221+0.010982 
[298]	train-rmse:0.082937+0.002589	test-rmse:0.193239+0.010986 
[299]	train-rmse:0.082703+0.002620	test-rmse:0.193250+0.010990 
[300]	train-rmse:0.082417+0.002588	test-rmse:0.193264+0.010962 
[301]	train-rmse:0.082188+0.002459	test-rmse:0.193250+0.010969 
[302]	train-rmse:0.081904+0.002458	test-rmse:0.193199+0.010965 
[303]	train-rmse:0.081728+0.002574	test-rmse:0.193166+0.010940 
[304]	train-rmse:0.081585+0.002437	test-rmse:0.193151+0.010947 
[305]	train-rmse:0.081588+0.002437	test-rmse:0.193150+0.010948 
[306]	train-rmse:0.081376+0.002558	test-rmse:0.193142+0.010954 
[307]	train-rmse:0.081190+0.002596	test-rmse:0.193144+0.010955 
[308]	train-rmse:0.081070+0.002716	test-rmse:0.193134+0.010954 
[309]	train-rmse:0.080858+0.002648	test-rmse:0.193109+0.010951 
[310]	train-rmse:0.080713+0.002620	test-rmse:0.193084+0.010962 
[311]	train-rmse:0.080448+0.002696	test-rmse:0.193078+0.010948 
[312]	train-rmse:0.080317+0.002749	test-rmse:0.193074+0.010946 
[313]	train-rmse:0.080188+0.002690	test-rmse:0.193083+0.010948 
[314]	train-rmse:0.080109+0.002641	test-rmse:0.193077+0.010949 
[315]	train-rmse:0.079984+0.002651	test-rmse:0.193075+0.010939 
[316]	train-rmse:0.079927+0.002678	test-rmse:0.193081+0.010932 
[317]	train-rmse:0.079650+0.002663	test-rmse:0.193058+0.010934 
[318]	train-rmse:0.079394+0.002736	test-rmse:0.193058+0.010978 
[319]	train-rmse:0.079070+0.002744	test-rmse:0.193044+0.010978 
[320]	train-rmse:0.078871+0.002661	test-rmse:0.193039+0.010974 
[321]	train-rmse:0.078804+0.002620	test-rmse:0.193044+0.010973 
[322]	train-rmse:0.078603+0.002512	test-rmse:0.193043+0.010975 
[323]	train-rmse:0.078355+0.002524	test-rmse:0.193038+0.010959 
[324]	train-rmse:0.078092+0.002515	test-rmse:0.193007+0.010995 
[325]	train-rmse:0.077889+0.002490	test-rmse:0.193002+0.010995 
[326]	train-rmse:0.077620+0.002352	test-rmse:0.192969+0.011011 
[327]	train-rmse:0.077503+0.002484	test-rmse:0.192988+0.011015 
[328]	train-rmse:0.077400+0.002442	test-rmse:0.192989+0.011015 
[329]	train-rmse:0.077127+0.002450	test-rmse:0.192993+0.011012 
[330]	train-rmse:0.076886+0.002527	test-rmse:0.192955+0.011045 
[331]	train-rmse:0.076698+0.002647	test-rmse:0.192968+0.011065 
[332]	train-rmse:0.076554+0.002691	test-rmse:0.192985+0.011093 
[333]	train-rmse:0.076305+0.002591	test-rmse:0.192982+0.011095 
[334]	train-rmse:0.076254+0.002672	test-rmse:0.192981+0.011093 
[335]	train-rmse:0.076023+0.002620	test-rmse:0.192968+0.011098 
[336]	train-rmse:0.075913+0.002708	test-rmse:0.192985+0.011130 
[337]	train-rmse:0.075742+0.002589	test-rmse:0.192958+0.011138 
[338]	train-rmse:0.075637+0.002604	test-rmse:0.192957+0.011140 
[339]	train-rmse:0.075456+0.002490	test-rmse:0.192943+0.011153 
[340]	train-rmse:0.075227+0.002398	test-rmse:0.192915+0.011168 
[341]	train-rmse:0.074970+0.002288	test-rmse:0.192887+0.011171 
[342]	train-rmse:0.074792+0.002259	test-rmse:0.192893+0.011172 
[343]	train-rmse:0.074672+0.002390	test-rmse:0.192892+0.011193 
[344]	train-rmse:0.074501+0.002454	test-rmse:0.192864+0.011178 
[345]	train-rmse:0.074445+0.002483	test-rmse:0.192863+0.011179 
[346]	train-rmse:0.074310+0.002393	test-rmse:0.192850+0.011194 
[347]	train-rmse:0.074198+0.002517	test-rmse:0.192858+0.011220 
[348]	train-rmse:0.074051+0.002605	test-rmse:0.192866+0.011233 
[349]	train-rmse:0.073939+0.002567	test-rmse:0.192864+0.011225 
[350]	train-rmse:0.073824+0.002543	test-rmse:0.192857+0.011232 
[351]	train-rmse:0.073772+0.002627	test-rmse:0.192859+0.011236 
[352]	train-rmse:0.073618+0.002587	test-rmse:0.192856+0.011236 
[353]	train-rmse:0.073386+0.002648	test-rmse:0.192848+0.011231 
[354]	train-rmse:0.073213+0.002690	test-rmse:0.192879+0.011258 
[355]	train-rmse:0.073034+0.002604	test-rmse:0.192885+0.011258 
[356]	train-rmse:0.072868+0.002694	test-rmse:0.192862+0.011253 
[357]	train-rmse:0.072679+0.002567	test-rmse:0.192852+0.011258 
[358]	train-rmse:0.072515+0.002666	test-rmse:0.192858+0.011275 
[359]	train-rmse:0.072363+0.002691	test-rmse:0.192857+0.011285 
[360]	train-rmse:0.072187+0.002759	test-rmse:0.192867+0.011304 
[361]	train-rmse:0.071972+0.002823	test-rmse:0.192866+0.011323 
[362]	train-rmse:0.071818+0.002827	test-rmse:0.192863+0.011319 
[363]	train-rmse:0.071665+0.002789	test-rmse:0.192860+0.011307 
[364]	train-rmse:0.071518+0.002713	test-rmse:0.192843+0.011317 
[365]	train-rmse:0.071306+0.002728	test-rmse:0.192832+0.011346 
[366]	train-rmse:0.071271+0.002724	test-rmse:0.192847+0.011347 
[367]	train-rmse:0.071219+0.002812	test-rmse:0.192851+0.011354 
[368]	train-rmse:0.071073+0.002837	test-rmse:0.192861+0.011371 
[369]	train-rmse:0.070947+0.002821	test-rmse:0.192844+0.011390 
[370]	train-rmse:0.070714+0.002735	test-rmse:0.192820+0.011389 
[371]	train-rmse:0.070606+0.002843	test-rmse:0.192827+0.011420 
[372]	train-rmse:0.070371+0.002849	test-rmse:0.192823+0.011442 
[373]	train-rmse:0.070272+0.002895	test-rmse:0.192837+0.011449 
[374]	train-rmse:0.070126+0.002971	test-rmse:0.192843+0.011462 
[375]	train-rmse:0.069917+0.002902	test-rmse:0.192831+0.011466 
[376]	train-rmse:0.069697+0.002966	test-rmse:0.192844+0.011442 
[377]	train-rmse:0.069482+0.002945	test-rmse:0.192824+0.011455 
[378]	train-rmse:0.069329+0.002873	test-rmse:0.192827+0.011459 
[379]	train-rmse:0.069121+0.002948	test-rmse:0.192821+0.011458 
[380]	train-rmse:0.068965+0.003055	test-rmse:0.192819+0.011452 
[381]	train-rmse:0.068879+0.003077	test-rmse:0.192814+0.011467 
[382]	train-rmse:0.068717+0.002957	test-rmse:0.192811+0.011464 
[383]	train-rmse:0.068597+0.002859	test-rmse:0.192816+0.011465 
[384]	train-rmse:0.068446+0.002866	test-rmse:0.192821+0.011474 
[385]	train-rmse:0.068370+0.002804	test-rmse:0.192818+0.011477 
[386]	train-rmse:0.068292+0.002747	test-rmse:0.192829+0.011473 
[387]	train-rmse:0.068228+0.002641	test-rmse:0.192820+0.011477 
[388]	train-rmse:0.068096+0.002700	test-rmse:0.192802+0.011452 
[389]	train-rmse:0.068014+0.002727	test-rmse:0.192804+0.011465 
[390]	train-rmse:0.067975+0.002661	test-rmse:0.192820+0.011457 
[391]	train-rmse:0.067828+0.002732	test-rmse:0.192797+0.011444 
[392]	train-rmse:0.067642+0.002741	test-rmse:0.192805+0.011427 
[393]	train-rmse:0.067543+0.002793	test-rmse:0.192813+0.011413 
[394]	train-rmse:0.067432+0.002820	test-rmse:0.192818+0.011418 
[395]	train-rmse:0.067325+0.002872	test-rmse:0.192834+0.011438 
[396]	train-rmse:0.067182+0.002931	test-rmse:0.192845+0.011442 
[397]	train-rmse:0.067084+0.002993	test-rmse:0.192838+0.011444 
[398]	train-rmse:0.066940+0.003068	test-rmse:0.192877+0.011493 
[399]	train-rmse:0.066901+0.003079	test-rmse:0.192890+0.011477 
[400]	train-rmse:0.066772+0.003030	test-rmse:0.192870+0.011489 
[401]	train-rmse:0.066544+0.003005	test-rmse:0.192871+0.011472 
[402]	train-rmse:0.066384+0.002959	test-rmse:0.192870+0.011476 
[403]	train-rmse:0.066226+0.002946	test-rmse:0.192875+0.011478 
[404]	train-rmse:0.066094+0.002868	test-rmse:0.192877+0.011476 
[405]	train-rmse:0.065859+0.002878	test-rmse:0.192908+0.011479 
[406]	train-rmse:0.065778+0.002884	test-rmse:0.192913+0.011480 
[407]	train-rmse:0.065660+0.002952	test-rmse:0.192922+0.011481 
[408]	train-rmse:0.065506+0.002868	test-rmse:0.192908+0.011480 
[409]	train-rmse:0.065381+0.002915	test-rmse:0.192922+0.011459 
[410]	train-rmse:0.065213+0.002840	test-rmse:0.192922+0.011459 
[411]	train-rmse:0.065090+0.002801	test-rmse:0.192931+0.011454 
[412]	train-rmse:0.064923+0.002861	test-rmse:0.192936+0.011462 
[413]	train-rmse:0.064851+0.002926	test-rmse:0.192932+0.011483 
[414]	train-rmse:0.064625+0.002942	test-rmse:0.192950+0.011492 
[415]	train-rmse:0.064579+0.002948	test-rmse:0.192943+0.011493 
[416]	train-rmse:0.064363+0.002919	test-rmse:0.192964+0.011512 
[417]	train-rmse:0.064266+0.002839	test-rmse:0.192968+0.011510 
[418]	train-rmse:0.064184+0.002845	test-rmse:0.192971+0.011511 
[419]	train-rmse:0.064011+0.002783	test-rmse:0.192981+0.011503 
[420]	train-rmse:0.063970+0.002708	test-rmse:0.192991+0.011498 
[421]	train-rmse:0.063890+0.002756	test-rmse:0.192990+0.011494 
[422]	train-rmse:0.063858+0.002764	test-rmse:0.192978+0.011497 
[423]	train-rmse:0.063779+0.002773	test-rmse:0.192978+0.011496 
[424]	train-rmse:0.063669+0.002841	test-rmse:0.192960+0.011474 
[425]	train-rmse:0.063585+0.002921	test-rmse:0.192975+0.011486 
[426]	train-rmse:0.063504+0.002844	test-rmse:0.192996+0.011480 
[427]	train-rmse:0.063353+0.002934	test-rmse:0.193007+0.011477 
[428]	train-rmse:0.063237+0.002901	test-rmse:0.193028+0.011463 
[429]	train-rmse:0.063158+0.002852	test-rmse:0.193039+0.011486 
[430]	train-rmse:0.063084+0.002848	test-rmse:0.193032+0.011485 
[431]	train-rmse:0.063087+0.002848	test-rmse:0.193031+0.011485 
[432]	train-rmse:0.062978+0.002907	test-rmse:0.193029+0.011496 
[433]	train-rmse:0.062902+0.002927	test-rmse:0.193042+0.011487 
[434]	train-rmse:0.062787+0.002852	test-rmse:0.193034+0.011489 
[435]	train-rmse:0.062592+0.002823	test-rmse:0.193022+0.011515 
[436]	train-rmse:0.062462+0.002743	test-rmse:0.193029+0.011511 
[437]	train-rmse:0.062417+0.002662	test-rmse:0.193040+0.011505 
[438]	train-rmse:0.062321+0.002662	test-rmse:0.193039+0.011508 
[439]	train-rmse:0.062200+0.002606	test-rmse:0.193076+0.011511 
[440]	train-rmse:0.062134+0.002602	test-rmse:0.193066+0.011510 
[441]	train-rmse:0.061996+0.002563	test-rmse:0.193058+0.011517 
Stopping. Best iteration:
[391]	train-rmse:0.067828+0.002732	test-rmse:0.192797+0.011444

> hgrid <-
+   dplyr::bind_cols(xgboost_params[index, ], dart.cv$evaluation_log[dart.cv$best_iteration, ], best_iter = dart.cv$best_iteration)
> 
> # write result
> fname <- file.path('data-raw', 'tune', year, 'array', paste0('tune_', index, '.tsv'))
> readr::write_tsv(hgrid, file = fname)
> 
