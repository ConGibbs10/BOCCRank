> 
> # parse arguments
> args <- R.utils::commandArgs(trailingOnly = FALSE, asValues = TRUE)
> index <- as.integer(args$index)
> year <- as.character(args$year)
> nreps <- as.integer(args$nreps)
> seed <- as.integer(args$seed)
> 
> # get number of cores
> wkrs <- length(future::availableWorkers())
> 
> # set seed
> set.seed(seed)
> 
> # read and prepare the cluster features
> fp <- file.path('data-raw', 'features', year)
> clf <-
+   read_features(fp, pattern = 'paris.', recursive = FALSE)
> clf <- prepare_features(
+   clf,
+   feature_map = feature_map,
+   category = c('response', 'bio', 'net'),
+   type = 'list',
+   exclusions = c(
+     'mg2_pairs_count',
+     'mg2_not_pairs_count',
+     'mg2_portion_families_recovered',
+     'cluster_origin',
+     'bocc_origin',
+     'cluster_method',
+     'subcluster_method',
+     'year',
+     'IDs',
+     'go_sig_threshold',
+     'num_new_edges_on_any_node',
+     'HPO_ratio'
+   ),
+   verbose = TRUE
+ )
c('HPO_ratio', 'IDs', 'bocc_origin', 'cluster_method', 'cluster_origin', 'go_sig_threshold', 'max_norm_cell_type_comma_sep_string', 'max_norm_disease_comma_sep_string', 'mg2_not_pairs_count', 'mg2_pairs_count', 'mg2_portion_families_recovered', 'num_new_edges_on_any_node', 'sig_go_enrichment_fdr_corrected_p_vals', 'sig_go_enrichment_p_vals', 'sig_go_enrichment_terms', 'subcluster_method', 'year')

> 
> # prepare grid of parameters
> xgboost_params <- dials::parameters(
+   nrounds = dials::trees(),
+   eta = dials::learn_rate(),
+   gamma = dials::loss_reduction(),
+   dials::tree_depth(),
+   subsample = dials::sample_prop(),
+   rate_drop = dials::dropout(),
+   skip_drop = dials::dropout()
+ )
> xgboost_params <-
+   dials::grid_max_entropy(xgboost_params, size = nreps)
> 
> # tune the dart booster
> dart.param <-
+   list(
+     booster = "dart",
+     objective = "reg:logistic",
+     eval_metric = "rmse",
+     nthread = wkrs,
+     max_depth = xgboost_params$tree_depth[index],
+     eta = xgboost_params$eta[index],
+     gamma = xgboost_params$gamma[index],
+     subsample = xgboost_params$subsample[index],
+     rate_drop = xgboost_params$rate_drop[index],
+     skip_drop = xgboost_params$skip_drop[index]
+   )
> dart.cv <- xgboost::xgb.cv(
+   params = dart.param,
+   nrounds = xgboost_params$nrounds[index],
+   data = as.matrix(clf[, -1]),
+   nfold = 5,
+   label = clf$snowballing_pvalue,
+   early_stopping_rounds = 50
+ )
[1]	train-rmse:0.382680+0.001055	test-rmse:0.382657+0.004188 
Multiple eval metrics are present. Will use test_rmse for early stopping.
Will train until test_rmse hasn't improved in 50 rounds.

[2]	train-rmse:0.382679+0.001055	test-rmse:0.382656+0.004188 
[3]	train-rmse:0.382678+0.001055	test-rmse:0.382654+0.004188 
[4]	train-rmse:0.382677+0.001055	test-rmse:0.382654+0.004188 
[5]	train-rmse:0.382676+0.001055	test-rmse:0.382652+0.004188 
[6]	train-rmse:0.382675+0.001055	test-rmse:0.382651+0.004188 
[7]	train-rmse:0.382674+0.001055	test-rmse:0.382650+0.004188 
[8]	train-rmse:0.382673+0.001055	test-rmse:0.382649+0.004188 
[9]	train-rmse:0.382672+0.001055	test-rmse:0.382648+0.004188 
[10]	train-rmse:0.382671+0.001055	test-rmse:0.382648+0.004188 
[11]	train-rmse:0.382670+0.001055	test-rmse:0.382647+0.004188 
[12]	train-rmse:0.382669+0.001055	test-rmse:0.382646+0.004188 
[13]	train-rmse:0.382668+0.001055	test-rmse:0.382645+0.004188 
[14]	train-rmse:0.382667+0.001054	test-rmse:0.382644+0.004189 
[15]	train-rmse:0.382667+0.001054	test-rmse:0.382644+0.004189 
[16]	train-rmse:0.382666+0.001054	test-rmse:0.382643+0.004188 
[17]	train-rmse:0.382665+0.001055	test-rmse:0.382643+0.004188 
[18]	train-rmse:0.382665+0.001055	test-rmse:0.382642+0.004188 
[19]	train-rmse:0.382664+0.001054	test-rmse:0.382641+0.004188 
[20]	train-rmse:0.382663+0.001054	test-rmse:0.382641+0.004188 
[21]	train-rmse:0.382662+0.001055	test-rmse:0.382640+0.004188 
[22]	train-rmse:0.382662+0.001055	test-rmse:0.382639+0.004188 
[23]	train-rmse:0.382661+0.001055	test-rmse:0.382639+0.004188 
[24]	train-rmse:0.382661+0.001054	test-rmse:0.382638+0.004188 
[25]	train-rmse:0.382660+0.001054	test-rmse:0.382638+0.004189 
[26]	train-rmse:0.382660+0.001054	test-rmse:0.382637+0.004189 
[27]	train-rmse:0.382659+0.001054	test-rmse:0.382637+0.004189 
[28]	train-rmse:0.382659+0.001054	test-rmse:0.382636+0.004189 
[29]	train-rmse:0.382658+0.001054	test-rmse:0.382636+0.004189 
[30]	train-rmse:0.382658+0.001054	test-rmse:0.382636+0.004189 
[31]	train-rmse:0.382658+0.001054	test-rmse:0.382635+0.004189 
[32]	train-rmse:0.382657+0.001054	test-rmse:0.382635+0.004189 
[33]	train-rmse:0.382657+0.001054	test-rmse:0.382634+0.004189 
[34]	train-rmse:0.382656+0.001054	test-rmse:0.382634+0.004189 
[35]	train-rmse:0.382656+0.001054	test-rmse:0.382634+0.004189 
[36]	train-rmse:0.382656+0.001054	test-rmse:0.382633+0.004189 
[37]	train-rmse:0.382655+0.001054	test-rmse:0.382633+0.004189 
[38]	train-rmse:0.382655+0.001054	test-rmse:0.382633+0.004189 
[39]	train-rmse:0.382655+0.001054	test-rmse:0.382632+0.004189 
[40]	train-rmse:0.382654+0.001054	test-rmse:0.382632+0.004189 
[41]	train-rmse:0.382654+0.001054	test-rmse:0.382632+0.004189 
[42]	train-rmse:0.382654+0.001054	test-rmse:0.382632+0.004189 
[43]	train-rmse:0.382653+0.001054	test-rmse:0.382631+0.004189 
[44]	train-rmse:0.382653+0.001054	test-rmse:0.382631+0.004189 
[45]	train-rmse:0.382653+0.001054	test-rmse:0.382631+0.004189 
[46]	train-rmse:0.382653+0.001054	test-rmse:0.382631+0.004189 
[47]	train-rmse:0.382653+0.001054	test-rmse:0.382630+0.004189 
[48]	train-rmse:0.382652+0.001054	test-rmse:0.382630+0.004189 
[49]	train-rmse:0.382652+0.001054	test-rmse:0.382630+0.004189 
[50]	train-rmse:0.382652+0.001054	test-rmse:0.382630+0.004189 
[51]	train-rmse:0.382651+0.001054	test-rmse:0.382629+0.004189 
[52]	train-rmse:0.382651+0.001053	test-rmse:0.382629+0.004189 
[53]	train-rmse:0.382651+0.001053	test-rmse:0.382629+0.004189 
[54]	train-rmse:0.382651+0.001053	test-rmse:0.382629+0.004189 
[55]	train-rmse:0.382651+0.001053	test-rmse:0.382629+0.004189 
[56]	train-rmse:0.382651+0.001053	test-rmse:0.382628+0.004189 
[57]	train-rmse:0.382650+0.001053	test-rmse:0.382628+0.004189 
[58]	train-rmse:0.382650+0.001053	test-rmse:0.382628+0.004189 
[59]	train-rmse:0.382650+0.001053	test-rmse:0.382628+0.004189 
[60]	train-rmse:0.382649+0.001053	test-rmse:0.382627+0.004190 
[61]	train-rmse:0.382649+0.001053	test-rmse:0.382627+0.004189 
[62]	train-rmse:0.382649+0.001053	test-rmse:0.382627+0.004190 
[63]	train-rmse:0.382648+0.001053	test-rmse:0.382627+0.004190 
[64]	train-rmse:0.382648+0.001053	test-rmse:0.382626+0.004190 
[65]	train-rmse:0.382648+0.001053	test-rmse:0.382626+0.004190 
[66]	train-rmse:0.382647+0.001053	test-rmse:0.382626+0.004190 
[67]	train-rmse:0.382647+0.001053	test-rmse:0.382625+0.004190 
[68]	train-rmse:0.382647+0.001053	test-rmse:0.382625+0.004190 
[69]	train-rmse:0.382647+0.001053	test-rmse:0.382625+0.004190 
[70]	train-rmse:0.382646+0.001053	test-rmse:0.382625+0.004190 
[71]	train-rmse:0.382646+0.001053	test-rmse:0.382624+0.004190 
[72]	train-rmse:0.382646+0.001053	test-rmse:0.382624+0.004190 
[73]	train-rmse:0.382646+0.001053	test-rmse:0.382624+0.004190 
[74]	train-rmse:0.382646+0.001053	test-rmse:0.382624+0.004190 
[75]	train-rmse:0.382645+0.001053	test-rmse:0.382624+0.004190 
[76]	train-rmse:0.382645+0.001053	test-rmse:0.382624+0.004190 
[77]	train-rmse:0.382645+0.001053	test-rmse:0.382623+0.004190 
[78]	train-rmse:0.382645+0.001053	test-rmse:0.382623+0.004190 
[79]	train-rmse:0.382645+0.001053	test-rmse:0.382623+0.004190 
[80]	train-rmse:0.382645+0.001053	test-rmse:0.382623+0.004190 
[81]	train-rmse:0.382645+0.001053	test-rmse:0.382623+0.004190 
[82]	train-rmse:0.382644+0.001053	test-rmse:0.382623+0.004190 
[83]	train-rmse:0.382644+0.001053	test-rmse:0.382623+0.004190 
[84]	train-rmse:0.382644+0.001053	test-rmse:0.382623+0.004190 
[85]	train-rmse:0.382644+0.001053	test-rmse:0.382622+0.004190 
[86]	train-rmse:0.382644+0.001053	test-rmse:0.382622+0.004189 
[87]	train-rmse:0.382644+0.001053	test-rmse:0.382622+0.004189 
[88]	train-rmse:0.382644+0.001053	test-rmse:0.382622+0.004189 
[89]	train-rmse:0.382643+0.001053	test-rmse:0.382622+0.004189 
[90]	train-rmse:0.382643+0.001053	test-rmse:0.382622+0.004189 
[91]	train-rmse:0.382643+0.001054	test-rmse:0.382621+0.004189 
[92]	train-rmse:0.382643+0.001054	test-rmse:0.382621+0.004189 
[93]	train-rmse:0.382643+0.001054	test-rmse:0.382621+0.004189 
[94]	train-rmse:0.382642+0.001054	test-rmse:0.382621+0.004189 
[95]	train-rmse:0.382642+0.001053	test-rmse:0.382620+0.004189 
[96]	train-rmse:0.382642+0.001053	test-rmse:0.382620+0.004189 
[97]	train-rmse:0.382642+0.001053	test-rmse:0.382620+0.004189 
[98]	train-rmse:0.382641+0.001053	test-rmse:0.382620+0.004189 
[99]	train-rmse:0.382641+0.001053	test-rmse:0.382619+0.004189 
[100]	train-rmse:0.382641+0.001053	test-rmse:0.382619+0.004189 
[101]	train-rmse:0.382641+0.001054	test-rmse:0.382619+0.004189 
[102]	train-rmse:0.382641+0.001054	test-rmse:0.382619+0.004189 
[103]	train-rmse:0.382640+0.001054	test-rmse:0.382619+0.004189 
[104]	train-rmse:0.382640+0.001054	test-rmse:0.382619+0.004189 
[105]	train-rmse:0.382640+0.001054	test-rmse:0.382619+0.004189 
[106]	train-rmse:0.382640+0.001054	test-rmse:0.382619+0.004189 
[107]	train-rmse:0.382640+0.001054	test-rmse:0.382619+0.004189 
[108]	train-rmse:0.382640+0.001054	test-rmse:0.382618+0.004189 
[109]	train-rmse:0.382640+0.001053	test-rmse:0.382618+0.004189 
[110]	train-rmse:0.382640+0.001053	test-rmse:0.382618+0.004189 
[111]	train-rmse:0.382639+0.001053	test-rmse:0.382618+0.004189 
[112]	train-rmse:0.382639+0.001054	test-rmse:0.382618+0.004189 
[113]	train-rmse:0.382639+0.001054	test-rmse:0.382618+0.004189 
[114]	train-rmse:0.382639+0.001054	test-rmse:0.382617+0.004188 
[115]	train-rmse:0.382639+0.001054	test-rmse:0.382617+0.004188 
[116]	train-rmse:0.382638+0.001054	test-rmse:0.382617+0.004188 
[117]	train-rmse:0.382638+0.001054	test-rmse:0.382617+0.004188 
[118]	train-rmse:0.382638+0.001054	test-rmse:0.382617+0.004188 
[119]	train-rmse:0.382638+0.001054	test-rmse:0.382617+0.004189 
[120]	train-rmse:0.382638+0.001054	test-rmse:0.382617+0.004189 
[121]	train-rmse:0.382638+0.001054	test-rmse:0.382616+0.004189 
[122]	train-rmse:0.382638+0.001054	test-rmse:0.382616+0.004189 
[123]	train-rmse:0.382638+0.001054	test-rmse:0.382616+0.004189 
[124]	train-rmse:0.382637+0.001054	test-rmse:0.382616+0.004189 
[125]	train-rmse:0.382637+0.001054	test-rmse:0.382616+0.004189 
[126]	train-rmse:0.382637+0.001053	test-rmse:0.382616+0.004189 
[127]	train-rmse:0.382637+0.001053	test-rmse:0.382615+0.004189 
[128]	train-rmse:0.382636+0.001054	test-rmse:0.382615+0.004189 
[129]	train-rmse:0.382636+0.001054	test-rmse:0.382615+0.004189 
[130]	train-rmse:0.382635+0.001054	test-rmse:0.382614+0.004188 
[131]	train-rmse:0.382635+0.001054	test-rmse:0.382614+0.004188 
[132]	train-rmse:0.382635+0.001054	test-rmse:0.382614+0.004188 
[133]	train-rmse:0.382634+0.001054	test-rmse:0.382613+0.004188 
[134]	train-rmse:0.382634+0.001054	test-rmse:0.382613+0.004188 
[135]	train-rmse:0.382634+0.001054	test-rmse:0.382613+0.004188 
[136]	train-rmse:0.382634+0.001054	test-rmse:0.382613+0.004188 
[137]	train-rmse:0.382634+0.001054	test-rmse:0.382613+0.004188 
[138]	train-rmse:0.382634+0.001054	test-rmse:0.382613+0.004189 
[139]	train-rmse:0.382633+0.001054	test-rmse:0.382612+0.004189 
[140]	train-rmse:0.382633+0.001054	test-rmse:0.382612+0.004189 
[141]	train-rmse:0.382633+0.001054	test-rmse:0.382612+0.004189 
[142]	train-rmse:0.382633+0.001054	test-rmse:0.382612+0.004189 
[143]	train-rmse:0.382633+0.001054	test-rmse:0.382612+0.004189 
[144]	train-rmse:0.382633+0.001054	test-rmse:0.382612+0.004189 
[145]	train-rmse:0.382633+0.001053	test-rmse:0.382612+0.004189 
[146]	train-rmse:0.382633+0.001054	test-rmse:0.382612+0.004189 
[147]	train-rmse:0.382633+0.001053	test-rmse:0.382612+0.004189 
[148]	train-rmse:0.382632+0.001053	test-rmse:0.382611+0.004189 
[149]	train-rmse:0.382632+0.001053	test-rmse:0.382611+0.004189 
[150]	train-rmse:0.382632+0.001053	test-rmse:0.382611+0.004189 
[151]	train-rmse:0.382632+0.001054	test-rmse:0.382611+0.004189 
[152]	train-rmse:0.382632+0.001054	test-rmse:0.382611+0.004189 
[153]	train-rmse:0.382632+0.001054	test-rmse:0.382611+0.004188 
[154]	train-rmse:0.382632+0.001054	test-rmse:0.382611+0.004188 
[155]	train-rmse:0.382632+0.001054	test-rmse:0.382611+0.004188 
[156]	train-rmse:0.382632+0.001054	test-rmse:0.382611+0.004188 
[157]	train-rmse:0.382632+0.001054	test-rmse:0.382611+0.004188 
[158]	train-rmse:0.382631+0.001055	test-rmse:0.382610+0.004188 
[159]	train-rmse:0.382631+0.001055	test-rmse:0.382610+0.004188 
[160]	train-rmse:0.382631+0.001055	test-rmse:0.382610+0.004187 
[161]	train-rmse:0.382631+0.001055	test-rmse:0.382610+0.004187 
[162]	train-rmse:0.382631+0.001055	test-rmse:0.382610+0.004187 
[163]	train-rmse:0.382631+0.001055	test-rmse:0.382610+0.004187 
[164]	train-rmse:0.382631+0.001055	test-rmse:0.382610+0.004187 
[165]	train-rmse:0.382630+0.001055	test-rmse:0.382610+0.004187 
[166]	train-rmse:0.382630+0.001055	test-rmse:0.382609+0.004187 
[167]	train-rmse:0.382630+0.001055	test-rmse:0.382609+0.004187 
[168]	train-rmse:0.382630+0.001055	test-rmse:0.382609+0.004187 
[169]	train-rmse:0.382630+0.001055	test-rmse:0.382609+0.004187 
[170]	train-rmse:0.382630+0.001055	test-rmse:0.382609+0.004187 
[171]	train-rmse:0.382630+0.001055	test-rmse:0.382609+0.004187 
[172]	train-rmse:0.382629+0.001056	test-rmse:0.382609+0.004187 
[173]	train-rmse:0.382629+0.001056	test-rmse:0.382608+0.004186 
[174]	train-rmse:0.382629+0.001056	test-rmse:0.382608+0.004186 
[175]	train-rmse:0.382629+0.001056	test-rmse:0.382608+0.004187 
[176]	train-rmse:0.382629+0.001056	test-rmse:0.382608+0.004187 
[177]	train-rmse:0.382629+0.001056	test-rmse:0.382608+0.004187 
[178]	train-rmse:0.382629+0.001056	test-rmse:0.382608+0.004187 
[179]	train-rmse:0.382628+0.001056	test-rmse:0.382607+0.004187 
[180]	train-rmse:0.382628+0.001056	test-rmse:0.382607+0.004187 
[181]	train-rmse:0.382628+0.001056	test-rmse:0.382607+0.004186 
[182]	train-rmse:0.382628+0.001056	test-rmse:0.382607+0.004186 
[183]	train-rmse:0.382628+0.001056	test-rmse:0.382607+0.004186 
[184]	train-rmse:0.382628+0.001056	test-rmse:0.382607+0.004186 
[185]	train-rmse:0.382627+0.001056	test-rmse:0.382607+0.004186 
[186]	train-rmse:0.382627+0.001056	test-rmse:0.382606+0.004186 
[187]	train-rmse:0.382627+0.001056	test-rmse:0.382606+0.004186 
[188]	train-rmse:0.382627+0.001056	test-rmse:0.382606+0.004186 
> hgrid <-
+   dplyr::bind_cols(xgboost_params[index, ], dart.cv$evaluation_log[dart.cv$best_iteration, ], best_iter = dart.cv$best_iteration)
> 
> # write result
> fname <- file.path('data-raw', 'tune', year, 'array', paste0('tune_', index, '.tsv'))
> readr::write_tsv(hgrid, file = fname)
> 
