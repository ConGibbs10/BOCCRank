> 
> # parse arguments
> args <- R.utils::commandArgs(trailingOnly = FALSE, asValues = TRUE)
> index <- as.integer(args$index)
> year <- as.character(args$year)
> nreps <- as.integer(args$nreps)
> seed <- as.integer(args$seed)
> 
> # get number of cores
> wkrs <- length(future::availableWorkers())
> 
> # set seed
> set.seed(seed)
> 
> # read and prepare the cluster features
> fp <- file.path('data-raw', 'features', year)
> clf <-
+   read_features(fp, pattern = 'paris.', recursive = FALSE)
> clf <- prepare_features(
+   clf,
+   feature_map = feature_map,
+   category = c('response', 'bio', 'net'),
+   type = 'list',
+   exclusions = c(
+     'mg2_pairs_count',
+     'mg2_not_pairs_count',
+     'mg2_portion_families_recovered',
+     'cluster_origin',
+     'bocc_origin',
+     'cluster_method',
+     'subcluster_method',
+     'year',
+     'IDs',
+     'go_sig_threshold',
+     'num_new_edges_on_any_node',
+     'HPO_ratio'
+   ),
+   verbose = TRUE
+ )
c('HPO_ratio', 'IDs', 'bocc_origin', 'cluster_method', 'cluster_origin', 'go_sig_threshold', 'max_norm_cell_type_comma_sep_string', 'max_norm_disease_comma_sep_string', 'mg2_not_pairs_count', 'mg2_pairs_count', 'mg2_portion_families_recovered', 'num_new_edges_on_any_node', 'sig_go_enrichment_fdr_corrected_p_vals', 'sig_go_enrichment_p_vals', 'sig_go_enrichment_terms', 'subcluster_method', 'year')

> 
> # prepare grid of parameters
> xgboost_params <- dials::parameters(
+   nrounds = dials::trees(),
+   eta = dials::learn_rate(),
+   gamma = dials::loss_reduction(),
+   dials::tree_depth(),
+   subsample = dials::sample_prop(),
+   rate_drop = dials::dropout(),
+   skip_drop = dials::dropout()
+ )
> xgboost_params <-
+   dials::grid_max_entropy(xgboost_params, size = nreps)
> 
> # tune the dart booster
> dart.param <-
+   list(
+     booster = "dart",
+     objective = "reg:logistic",
+     eval_metric = "rmse",
+     nthread = wkrs,
+     max_depth = xgboost_params$tree_depth[index],
+     eta = xgboost_params$eta[index],
+     gamma = xgboost_params$gamma[index],
+     subsample = xgboost_params$subsample[index],
+     rate_drop = xgboost_params$rate_drop[index],
+     skip_drop = xgboost_params$skip_drop[index]
+   )
> dart.cv <- xgboost::xgb.cv(
+   params = dart.param,
+   nrounds = xgboost_params$nrounds[index],
+   data = as.matrix(clf[, -1]),
+   nfold = 5,
+   label = clf$snowballing_pvalue,
+   early_stopping_rounds = 50
+ )
[1]	train-rmse:0.382638+0.001055	test-rmse:0.382615+0.004189 
Multiple eval metrics are present. Will use test_rmse for early stopping.
Will train until test_rmse hasn't improved in 50 rounds.

[2]	train-rmse:0.382595+0.001054	test-rmse:0.382573+0.004188 
[3]	train-rmse:0.382565+0.001047	test-rmse:0.382544+0.004196 
[4]	train-rmse:0.382539+0.001055	test-rmse:0.382518+0.004187 
[5]	train-rmse:0.382528+0.001054	test-rmse:0.382507+0.004188 
[6]	train-rmse:0.382511+0.001052	test-rmse:0.382490+0.004190 
[7]	train-rmse:0.382497+0.001050	test-rmse:0.382476+0.004193 
[8]	train-rmse:0.382490+0.001050	test-rmse:0.382469+0.004193 
[9]	train-rmse:0.382477+0.001043	test-rmse:0.382456+0.004200 
[10]	train-rmse:0.382464+0.001042	test-rmse:0.382444+0.004202 
[11]	train-rmse:0.382451+0.001042	test-rmse:0.382431+0.004201 
[12]	train-rmse:0.382439+0.001056	test-rmse:0.382419+0.004186 
[13]	train-rmse:0.382419+0.001056	test-rmse:0.382400+0.004187 
[14]	train-rmse:0.382408+0.001070	test-rmse:0.382389+0.004174 
[15]	train-rmse:0.382389+0.001062	test-rmse:0.382370+0.004183 
[16]	train-rmse:0.382377+0.001054	test-rmse:0.382359+0.004189 
[17]	train-rmse:0.382366+0.001053	test-rmse:0.382347+0.004191 
[18]	train-rmse:0.382363+0.001053	test-rmse:0.382345+0.004191 
[19]	train-rmse:0.382352+0.001047	test-rmse:0.382334+0.004197 
[20]	train-rmse:0.382342+0.001041	test-rmse:0.382324+0.004202 
[21]	train-rmse:0.382339+0.001041	test-rmse:0.382322+0.004202 
[22]	train-rmse:0.382321+0.001035	test-rmse:0.382304+0.004207 
[23]	train-rmse:0.382310+0.001034	test-rmse:0.382293+0.004210 
[24]	train-rmse:0.382308+0.001034	test-rmse:0.382291+0.004209 
[25]	train-rmse:0.382289+0.001028	test-rmse:0.382273+0.004214 
[26]	train-rmse:0.382287+0.001028	test-rmse:0.382271+0.004214 
[27]	train-rmse:0.382276+0.001019	test-rmse:0.382260+0.004223 
[28]	train-rmse:0.382266+0.001012	test-rmse:0.382250+0.004229 
[29]	train-rmse:0.382264+0.001012	test-rmse:0.382249+0.004229 
[30]	train-rmse:0.382254+0.001006	test-rmse:0.382239+0.004235 
[31]	train-rmse:0.382244+0.001007	test-rmse:0.382229+0.004234 
[32]	train-rmse:0.382242+0.001007	test-rmse:0.382228+0.004234 
[33]	train-rmse:0.382232+0.001006	test-rmse:0.382217+0.004237 
[34]	train-rmse:0.382205+0.001021	test-rmse:0.382190+0.004223 
[35]	train-rmse:0.382204+0.001021	test-rmse:0.382189+0.004223 
[36]	train-rmse:0.382202+0.001021	test-rmse:0.382188+0.004222 
[37]	train-rmse:0.382201+0.001021	test-rmse:0.382186+0.004223 
[38]	train-rmse:0.382191+0.001015	test-rmse:0.382177+0.004229 
[39]	train-rmse:0.382165+0.001021	test-rmse:0.382151+0.004221 
[40]	train-rmse:0.382164+0.001021	test-rmse:0.382150+0.004221 
[41]	train-rmse:0.382162+0.001021	test-rmse:0.382149+0.004221 
[42]	train-rmse:0.382161+0.001021	test-rmse:0.382148+0.004221 
[43]	train-rmse:0.382151+0.001012	test-rmse:0.382138+0.004229 
[44]	train-rmse:0.382142+0.001011	test-rmse:0.382129+0.004231 
[45]	train-rmse:0.382125+0.001001	test-rmse:0.382111+0.004241 
[46]	train-rmse:0.382115+0.000995	test-rmse:0.382103+0.004246 
[47]	train-rmse:0.382106+0.000994	test-rmse:0.382094+0.004249 
[48]	train-rmse:0.382079+0.000979	test-rmse:0.382068+0.004262 
[49]	train-rmse:0.382062+0.000979	test-rmse:0.382051+0.004263 
[50]	train-rmse:0.382061+0.000979	test-rmse:0.382050+0.004263 
[51]	train-rmse:0.382052+0.000980	test-rmse:0.382041+0.004262 
[52]	train-rmse:0.382042+0.000971	test-rmse:0.382032+0.004270 
[53]	train-rmse:0.382024+0.000963	test-rmse:0.382014+0.004277 
[54]	train-rmse:0.382023+0.000963	test-rmse:0.382013+0.004277 
[55]	train-rmse:0.382005+0.000977	test-rmse:0.381996+0.004264 
[56]	train-rmse:0.381987+0.000970	test-rmse:0.381978+0.004273 
[57]	train-rmse:0.381986+0.000970	test-rmse:0.381977+0.004273 
[58]	train-rmse:0.381960+0.000962	test-rmse:0.381951+0.004282 
[59]	train-rmse:0.381959+0.000962	test-rmse:0.381950+0.004282 
[60]	train-rmse:0.381949+0.000955	test-rmse:0.381941+0.004288 
[61]	train-rmse:0.381923+0.000963	test-rmse:0.381915+0.004282 
[62]	train-rmse:0.381905+0.000947	test-rmse:0.381898+0.004296 
[63]	train-rmse:0.381904+0.000947	test-rmse:0.381897+0.004296 
[64]	train-rmse:0.381895+0.000946	test-rmse:0.381887+0.004299 
[65]	train-rmse:0.381894+0.000946	test-rmse:0.381886+0.004299 
[66]	train-rmse:0.381893+0.000946	test-rmse:0.381886+0.004299 
[67]	train-rmse:0.381892+0.000946	test-rmse:0.381885+0.004299 
[68]	train-rmse:0.381892+0.000946	test-rmse:0.381884+0.004299 
[69]	train-rmse:0.381882+0.000940	test-rmse:0.381875+0.004305 
[70]	train-rmse:0.381881+0.000940	test-rmse:0.381875+0.004305 
[71]	train-rmse:0.381872+0.000955	test-rmse:0.381865+0.004289 
[72]	train-rmse:0.381863+0.000949	test-rmse:0.381857+0.004295 
[73]	train-rmse:0.381863+0.000949	test-rmse:0.381856+0.004295 
[74]	train-rmse:0.381862+0.000949	test-rmse:0.381855+0.004295 
[75]	train-rmse:0.381861+0.000949	test-rmse:0.381855+0.004295 
[76]	train-rmse:0.381842+0.000933	test-rmse:0.381837+0.004310 
[77]	train-rmse:0.381833+0.000933	test-rmse:0.381827+0.004313 
[78]	train-rmse:0.381832+0.000933	test-rmse:0.381826+0.004313 
[79]	train-rmse:0.381832+0.000933	test-rmse:0.381826+0.004313 
[80]	train-rmse:0.381814+0.000948	test-rmse:0.381808+0.004296 
[81]	train-rmse:0.381805+0.000939	test-rmse:0.381800+0.004303 
[82]	train-rmse:0.381796+0.000934	test-rmse:0.381791+0.004309 
[83]	train-rmse:0.381795+0.000934	test-rmse:0.381790+0.004309 
[84]	train-rmse:0.381785+0.000934	test-rmse:0.381781+0.004308 
[85]	train-rmse:0.381776+0.000933	test-rmse:0.381771+0.004311 
[86]	train-rmse:0.381767+0.000924	test-rmse:0.381762+0.004319 
[87]	train-rmse:0.381766+0.000924	test-rmse:0.381762+0.004319 
[88]	train-rmse:0.381757+0.000940	test-rmse:0.381752+0.004302 
[89]	train-rmse:0.381739+0.000955	test-rmse:0.381734+0.004289 
[90]	train-rmse:0.381730+0.000949	test-rmse:0.381726+0.004294 
[91]	train-rmse:0.381721+0.000940	test-rmse:0.381717+0.004302 
[92]	train-rmse:0.381720+0.000940	test-rmse:0.381717+0.004302 
[93]	train-rmse:0.381702+0.000940	test-rmse:0.381699+0.004304 
[94]	train-rmse:0.381694+0.000940	test-rmse:0.381690+0.004306 
[95]	train-rmse:0.381693+0.000940	test-rmse:0.381689+0.004306 
[96]	train-rmse:0.381693+0.000940	test-rmse:0.381689+0.004306 
[97]	train-rmse:0.381675+0.000956	test-rmse:0.381671+0.004288 
[98]	train-rmse:0.381657+0.000939	test-rmse:0.381653+0.004303 
[99]	train-rmse:0.381648+0.000930	test-rmse:0.381645+0.004311 
[100]	train-rmse:0.381631+0.000946	test-rmse:0.381628+0.004294 
[101]	train-rmse:0.381630+0.000946	test-rmse:0.381627+0.004294 
[102]	train-rmse:0.381621+0.000961	test-rmse:0.381619+0.004279 
[103]	train-rmse:0.381621+0.000961	test-rmse:0.381618+0.004279 
[104]	train-rmse:0.381612+0.000952	test-rmse:0.381609+0.004287 
[105]	train-rmse:0.381611+0.000952	test-rmse:0.381608+0.004287 
[106]	train-rmse:0.381594+0.000952	test-rmse:0.381591+0.004289 
[107]	train-rmse:0.381576+0.000946	test-rmse:0.381574+0.004293 
[108]	train-rmse:0.381558+0.000952	test-rmse:0.381557+0.004286 
[109]	train-rmse:0.381549+0.000943	test-rmse:0.381547+0.004294 
[110]	train-rmse:0.381524+0.000952	test-rmse:0.381523+0.004288 
[111]	train-rmse:0.381498+0.000943	test-rmse:0.381498+0.004297 
[112]	train-rmse:0.381489+0.000934	test-rmse:0.381489+0.004305 
[113]	train-rmse:0.381480+0.000925	test-rmse:0.381479+0.004314 
[114]	train-rmse:0.381471+0.000924	test-rmse:0.381470+0.004317 
[115]	train-rmse:0.381462+0.000924	test-rmse:0.381461+0.004320 
[116]	train-rmse:0.381461+0.000924	test-rmse:0.381461+0.004319 
[117]	train-rmse:0.381444+0.000908	test-rmse:0.381444+0.004334 
[118]	train-rmse:0.381443+0.000908	test-rmse:0.381443+0.004334 
[119]	train-rmse:0.381426+0.000901	test-rmse:0.381426+0.004342 
[120]	train-rmse:0.381426+0.000901	test-rmse:0.381426+0.004342 
[121]	train-rmse:0.381408+0.000895	test-rmse:0.381409+0.004351 
[122]	train-rmse:0.381398+0.000888	test-rmse:0.381400+0.004357 
[123]	train-rmse:0.381390+0.000879	test-rmse:0.381392+0.004365 
[124]	train-rmse:0.381380+0.000896	test-rmse:0.381382+0.004348 
[125]	train-rmse:0.381354+0.000880	test-rmse:0.381356+0.004361 
[126]	train-rmse:0.381344+0.000880	test-rmse:0.381347+0.004360 
[127]	train-rmse:0.381344+0.000880	test-rmse:0.381347+0.004360 
[128]	train-rmse:0.381335+0.000895	test-rmse:0.381339+0.004345 
[129]	train-rmse:0.381335+0.000896	test-rmse:0.381338+0.004345 
[130]	train-rmse:0.381334+0.000895	test-rmse:0.381338+0.004345 
[131]	train-rmse:0.381334+0.000895	test-rmse:0.381337+0.004345 
[132]	train-rmse:0.381325+0.000896	test-rmse:0.381329+0.004343 
[133]	train-rmse:0.381316+0.000895	test-rmse:0.381320+0.004346 
[134]	train-rmse:0.381307+0.000895	test-rmse:0.381311+0.004349 
[135]	train-rmse:0.381307+0.000895	test-rmse:0.381310+0.004349 
[136]	train-rmse:0.381307+0.000895	test-rmse:0.381310+0.004349 
[137]	train-rmse:0.381306+0.000895	test-rmse:0.381310+0.004349 
[138]	train-rmse:0.381306+0.000895	test-rmse:0.381309+0.004349 
[139]	train-rmse:0.381306+0.000895	test-rmse:0.381309+0.004349 
[140]	train-rmse:0.381279+0.000902	test-rmse:0.381283+0.004340 
[141]	train-rmse:0.381279+0.000902	test-rmse:0.381283+0.004340 
[142]	train-rmse:0.381270+0.000902	test-rmse:0.381274+0.004342 
[143]	train-rmse:0.381270+0.000902	test-rmse:0.381273+0.004342 
[144]	train-rmse:0.381252+0.000896	test-rmse:0.381256+0.004347 
[145]	train-rmse:0.381226+0.000895	test-rmse:0.381231+0.004346 
[146]	train-rmse:0.381217+0.000895	test-rmse:0.381222+0.004345 
[147]	train-rmse:0.381191+0.000911	test-rmse:0.381196+0.004332 
[148]	train-rmse:0.381191+0.000911	test-rmse:0.381196+0.004332 
[149]	train-rmse:0.381173+0.000919	test-rmse:0.381179+0.004322 
[150]	train-rmse:0.381164+0.000920	test-rmse:0.381170+0.004321 
[151]	train-rmse:0.381147+0.000914	test-rmse:0.381154+0.004326 
[152]	train-rmse:0.381146+0.000914	test-rmse:0.381153+0.004326 
[153]	train-rmse:0.381138+0.000929	test-rmse:0.381145+0.004310 
[154]	train-rmse:0.381120+0.000920	test-rmse:0.381127+0.004318 
[155]	train-rmse:0.381103+0.000937	test-rmse:0.381110+0.004301 
[156]	train-rmse:0.381102+0.000937	test-rmse:0.381110+0.004301 
[157]	train-rmse:0.381093+0.000953	test-rmse:0.381100+0.004284 
[158]	train-rmse:0.381076+0.000945	test-rmse:0.381083+0.004291 
[159]	train-rmse:0.381067+0.000939	test-rmse:0.381075+0.004296 
[160]	train-rmse:0.381059+0.000953	test-rmse:0.381067+0.004282 
[161]	train-rmse:0.381050+0.000955	test-rmse:0.381059+0.004281 
[162]	train-rmse:0.381041+0.000953	test-rmse:0.381049+0.004284 
[163]	train-rmse:0.381023+0.000954	test-rmse:0.381032+0.004286 
[164]	train-rmse:0.381014+0.000953	test-rmse:0.381023+0.004288 
[165]	train-rmse:0.381006+0.000967	test-rmse:0.381015+0.004274 
[166]	train-rmse:0.380980+0.000984	test-rmse:0.380989+0.004260 
[167]	train-rmse:0.380980+0.000984	test-rmse:0.380988+0.004260 
[168]	train-rmse:0.380980+0.000984	test-rmse:0.380988+0.004260 
[169]	train-rmse:0.380971+0.000998	test-rmse:0.380979+0.004244 
[170]	train-rmse:0.380971+0.000998	test-rmse:0.380979+0.004244 
[171]	train-rmse:0.380961+0.000991	test-rmse:0.380970+0.004250 
[172]	train-rmse:0.380961+0.000991	test-rmse:0.380970+0.004250 
[173]	train-rmse:0.380953+0.001005	test-rmse:0.380962+0.004235 
[174]	train-rmse:0.380927+0.000998	test-rmse:0.380936+0.004244 
[175]	train-rmse:0.380918+0.000999	test-rmse:0.380927+0.004244 
[176]	train-rmse:0.380908+0.000990	test-rmse:0.380918+0.004252 
[177]	train-rmse:0.380900+0.000992	test-rmse:0.380909+0.004251 
[178]	train-rmse:0.380891+0.000983	test-rmse:0.380901+0.004259 
[179]	train-rmse:0.380891+0.000983	test-rmse:0.380901+0.004259 
[180]	train-rmse:0.380891+0.000983	test-rmse:0.380900+0.004259 
[181]	train-rmse:0.380882+0.000985	test-rmse:0.380892+0.004258 
[182]	train-rmse:0.380874+0.000978	test-rmse:0.380884+0.004264 
[183]	train-rmse:0.380865+0.000971	test-rmse:0.380876+0.004270 
[184]	train-rmse:0.380864+0.000971	test-rmse:0.380875+0.004270 
[185]	train-rmse:0.380856+0.000974	test-rmse:0.380867+0.004269 
[186]	train-rmse:0.380847+0.000965	test-rmse:0.380859+0.004276 
[187]	train-rmse:0.380847+0.000965	test-rmse:0.380859+0.004276 
[188]	train-rmse:0.380847+0.000965	test-rmse:0.380859+0.004276 
[189]	train-rmse:0.380838+0.000964	test-rmse:0.380849+0.004279 
[190]	train-rmse:0.380838+0.000964	test-rmse:0.380849+0.004279 
[191]	train-rmse:0.380829+0.000956	test-rmse:0.380841+0.004285 
[192]	train-rmse:0.380819+0.000950	test-rmse:0.380833+0.004291 
[193]	train-rmse:0.380819+0.000950	test-rmse:0.380832+0.004291 
[194]	train-rmse:0.380810+0.000965	test-rmse:0.380823+0.004274 
[195]	train-rmse:0.380810+0.000965	test-rmse:0.380823+0.004274 
[196]	train-rmse:0.380801+0.000980	test-rmse:0.380814+0.004258 
[197]	train-rmse:0.380792+0.000982	test-rmse:0.380806+0.004258 
[198]	train-rmse:0.380784+0.000976	test-rmse:0.380798+0.004263 
[199]	train-rmse:0.380774+0.000969	test-rmse:0.380789+0.004270 
[200]	train-rmse:0.380774+0.000969	test-rmse:0.380789+0.004270 
[201]	train-rmse:0.380774+0.000969	test-rmse:0.380788+0.004270 
[202]	train-rmse:0.380764+0.000963	test-rmse:0.380780+0.004276 
[203]	train-rmse:0.380764+0.000963	test-rmse:0.380780+0.004276 
[204]	train-rmse:0.380764+0.000963	test-rmse:0.380780+0.004276 
[205]	train-rmse:0.380764+0.000963	test-rmse:0.380779+0.004276 
[206]	train-rmse:0.380755+0.000978	test-rmse:0.380770+0.004260 
[207]	train-rmse:0.380737+0.000984	test-rmse:0.380753+0.004252 
[208]	train-rmse:0.380737+0.000984	test-rmse:0.380753+0.004252 
[209]	train-rmse:0.380720+0.000980	test-rmse:0.380737+0.004257 
[210]	train-rmse:0.380711+0.000982	test-rmse:0.380728+0.004256 
[211]	train-rmse:0.380711+0.000982	test-rmse:0.380728+0.004256 
[212]	train-rmse:0.380710+0.000982	test-rmse:0.380727+0.004256 
[213]	train-rmse:0.380701+0.000977	test-rmse:0.380719+0.004263 
[214]	train-rmse:0.380701+0.000977	test-rmse:0.380719+0.004263 
[215]	train-rmse:0.380692+0.000971	test-rmse:0.380710+0.004269 
[216]	train-rmse:0.380683+0.000969	test-rmse:0.380702+0.004271 
[217]	train-rmse:0.380683+0.000969	test-rmse:0.380701+0.004271 
[218]	train-rmse:0.380674+0.000967	test-rmse:0.380693+0.004274 
[219]	train-rmse:0.380674+0.000967	test-rmse:0.380693+0.004274 
[220]	train-rmse:0.380665+0.000982	test-rmse:0.380684+0.004258 
[221]	train-rmse:0.380665+0.000982	test-rmse:0.380684+0.004258 
[222]	train-rmse:0.380665+0.000982	test-rmse:0.380684+0.004258 
[223]	train-rmse:0.380665+0.000982	test-rmse:0.380683+0.004258 
[224]	train-rmse:0.380665+0.000982	test-rmse:0.380683+0.004258 
[225]	train-rmse:0.380647+0.000979	test-rmse:0.380667+0.004264 
[226]	train-rmse:0.380639+0.000978	test-rmse:0.380659+0.004266 
[227]	train-rmse:0.380622+0.000979	test-rmse:0.380641+0.004268 
[228]	train-rmse:0.380595+0.000965	test-rmse:0.380616+0.004281 
[229]	train-rmse:0.380587+0.000955	test-rmse:0.380607+0.004289 
[230]	train-rmse:0.380577+0.000953	test-rmse:0.380598+0.004291 
[231]	train-rmse:0.380560+0.000971	test-rmse:0.380581+0.004275 
[232]	train-rmse:0.380559+0.000971	test-rmse:0.380581+0.004275 
[233]	train-rmse:0.380542+0.000980	test-rmse:0.380564+0.004266 
[234]	train-rmse:0.380524+0.000973	test-rmse:0.380547+0.004275 
[235]	train-rmse:0.380514+0.000962	test-rmse:0.380538+0.004283 
[236]	train-rmse:0.380506+0.000957	test-rmse:0.380529+0.004289 
[237]	train-rmse:0.380505+0.000957	test-rmse:0.380529+0.004289 
[238]	train-rmse:0.380488+0.000950	test-rmse:0.380511+0.004298 
[239]	train-rmse:0.380479+0.000949	test-rmse:0.380502+0.004301 
[240]	train-rmse:0.380462+0.000950	test-rmse:0.380485+0.004303 
[241]	train-rmse:0.380436+0.000962	test-rmse:0.380460+0.004293 
[242]	train-rmse:0.380426+0.000958	test-rmse:0.380452+0.004299 
[243]	train-rmse:0.380426+0.000958	test-rmse:0.380451+0.004299 
[244]	train-rmse:0.380426+0.000958	test-rmse:0.380451+0.004299 
[245]	train-rmse:0.380426+0.000958	test-rmse:0.380451+0.004299 
[246]	train-rmse:0.380426+0.000958	test-rmse:0.380451+0.004299 
[247]	train-rmse:0.380426+0.000958	test-rmse:0.380451+0.004299 
[248]	train-rmse:0.380417+0.000946	test-rmse:0.380442+0.004307 
[249]	train-rmse:0.380390+0.000929	test-rmse:0.380416+0.004324 
[250]	train-rmse:0.380381+0.000928	test-rmse:0.380407+0.004327 
[251]	train-rmse:0.380364+0.000941	test-rmse:0.380390+0.004314 
[252]	train-rmse:0.380364+0.000941	test-rmse:0.380389+0.004314 
[253]	train-rmse:0.380364+0.000941	test-rmse:0.380389+0.004314 
[254]	train-rmse:0.380363+0.000941	test-rmse:0.380389+0.004314 
[255]	train-rmse:0.380338+0.000945	test-rmse:0.380364+0.004307 
[256]	train-rmse:0.380321+0.000954	test-rmse:0.380347+0.004298 
[257]	train-rmse:0.380303+0.000950	test-rmse:0.380329+0.004308 
[258]	train-rmse:0.380294+0.000938	test-rmse:0.380320+0.004316 
[259]	train-rmse:0.380286+0.000938	test-rmse:0.380311+0.004318 
[260]	train-rmse:0.380277+0.000938	test-rmse:0.380302+0.004322 
[261]	train-rmse:0.380268+0.000939	test-rmse:0.380294+0.004324 
[262]	train-rmse:0.380268+0.000939	test-rmse:0.380293+0.004325 
[263]	train-rmse:0.380250+0.000941	test-rmse:0.380275+0.004316 
[264]	train-rmse:0.380250+0.000941	test-rmse:0.380275+0.004316 
[265]	train-rmse:0.380250+0.000941	test-rmse:0.380275+0.004316 
[266]	train-rmse:0.380241+0.000942	test-rmse:0.380266+0.004319 
[267]	train-rmse:0.380232+0.000937	test-rmse:0.380258+0.004325 
[268]	train-rmse:0.380232+0.000937	test-rmse:0.380258+0.004325 
[269]	train-rmse:0.380223+0.000932	test-rmse:0.380249+0.004332 
[270]	train-rmse:0.380205+0.000948	test-rmse:0.380232+0.004315 
[271]	train-rmse:0.380179+0.000959	test-rmse:0.380207+0.004305 
[272]	train-rmse:0.380179+0.000959	test-rmse:0.380207+0.004305 
[273]	train-rmse:0.380171+0.000973	test-rmse:0.380199+0.004290 
[274]	train-rmse:0.380154+0.000957	test-rmse:0.380183+0.004304 
[275]	train-rmse:0.380128+0.000942	test-rmse:0.380158+0.004317 
[276]	train-rmse:0.380127+0.000942	test-rmse:0.380158+0.004317 
[277]	train-rmse:0.380127+0.000942	test-rmse:0.380157+0.004317 
[278]	train-rmse:0.380118+0.000943	test-rmse:0.380148+0.004316 
[279]	train-rmse:0.380118+0.000943	test-rmse:0.380148+0.004316 
[280]	train-rmse:0.380091+0.000957	test-rmse:0.380122+0.004303 
[281]	train-rmse:0.380091+0.000957	test-rmse:0.380122+0.004303 
[282]	train-rmse:0.380091+0.000957	test-rmse:0.380122+0.004303 
[283]	train-rmse:0.380090+0.000957	test-rmse:0.380122+0.004303 
[284]	train-rmse:0.380090+0.000957	test-rmse:0.380121+0.004303 
[285]	train-rmse:0.380081+0.000958	test-rmse:0.380113+0.004302 
[286]	train-rmse:0.380072+0.000973	test-rmse:0.380104+0.004286 
[287]	train-rmse:0.380055+0.000969	test-rmse:0.380087+0.004295 
[288]	train-rmse:0.380055+0.000969	test-rmse:0.380086+0.004295 
[289]	train-rmse:0.380046+0.000965	test-rmse:0.380078+0.004302 
> hgrid <-
+   dplyr::bind_cols(xgboost_params[index, ], dart.cv$evaluation_log[dart.cv$best_iteration, ], best_iter = dart.cv$best_iteration)
> 
> # write result
> fname <- file.path('data-raw', 'tune', year, 'array', paste0('tune_', index, '.tsv'))
> readr::write_tsv(hgrid, file = fname)
> 
